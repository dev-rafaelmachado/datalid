"""
ðŸ‹ï¸ Trainer YOLO
Sistema de treinamento com monitoramento e mÃ©tricas.
"""

from pathlib import Path
from typing import Dict, List, Optional, Union, Any, Callable
import time
import json
from datetime import datetime, timedelta
from dataclasses import dataclass, field

import torch
import yaml
from loguru import logger

try:
    from ultralytics import YOLO
    from ultralytics.utils.callbacks import add_integration_callbacks
except ImportError:
    logger.error("Ultralytics nÃ£o instalado. Instale com: pip install ultralytics")
    raise

from ..core.config import config
from ..core.exceptions import (
    TrainingError, ModelNotFoundError, DatasetNotFoundError,
    GPUNotAvailableError, InsufficientMemoryError
)
from .config import YOLOConfig, TrainingConfig
from .utils import validate_gpu, optimize_batch_size, create_data_yaml


@dataclass
class TrainingMetrics:
    """MÃ©tricas de treinamento."""
    
    # InformaÃ§Ãµes gerais
    model_name: str = ""
    dataset_path: str = ""
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    total_epochs: int = 0
    completed_epochs: int = 0
    
    # MÃ©tricas por Ã©poca
    train_losses: List[float] = field(default_factory=list)
    val_losses: List[float] = field(default_factory=list)
    map50: List[float] = field(default_factory=list)  # mAP@0.5
    map50_95: List[float] = field(default_factory=list)  # mAP@0.5:0.95
    precision: List[float] = field(default_factory=list)
    recall: List[float] = field(default_factory=list)
    
    # Melhor modelo
    best_epoch: int = 0
    best_map50: float = 0.0
    best_map50_95: float = 0.0
    
    # Hardware
    gpu_memory_used: List[float] = field(default_factory=list)
    training_speed: float = 0.0  # imagens/segundo
    
    def __post_init__(self):
        if self.start_time is None:
            self.start_time = datetime.now()
    
    @property
    def duration(self) -> Optional[timedelta]:
        """DuraÃ§Ã£o do treinamento."""
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        elif self.start_time:
            return datetime.now() - self.start_time
        return None
    
    @property
    def progress(self) -> float:
        """Progresso do treinamento (0-1)."""
        if self.total_epochs > 0:
            return min(self.completed_epochs / self.total_epochs, 1.0)
        return 0.0
    
    @property
    def eta(self) -> Optional[timedelta]:
        """Tempo estimado para conclusÃ£o."""
        if self.progress > 0 and self.duration:
            total_estimated = self.duration / self.progress
            return total_estimated - self.duration
        return None
    
    def update_epoch(self, epoch: int, metrics: Dict[str, float]) -> None:
        """Atualiza mÃ©tricas da Ã©poca."""
        self.completed_epochs = epoch + 1
        
        # Adicionar mÃ©tricas
        self.train_losses.append(metrics.get('train/loss', 0.0))
        self.val_losses.append(metrics.get('val/loss', 0.0))
        self.map50.append(metrics.get('metrics/mAP50(B)', 0.0))
        self.map50_95.append(metrics.get('metrics/mAP50-95(B)', 0.0))
        self.precision.append(metrics.get('metrics/precision(B)', 0.0))
        self.recall.append(metrics.get('metrics/recall(B)', 0.0))
        
        # Atualizar melhor modelo
        current_map50 = metrics.get('metrics/mAP50(B)', 0.0)
        if current_map50 > self.best_map50:
            self.best_epoch = epoch
            self.best_map50 = current_map50
            self.best_map50_95 = metrics.get('metrics/mAP50-95(B)', 0.0)
        
        # GPU memory
        if torch.cuda.is_available():
            gpu_mem = torch.cuda.memory_allocated() / 1024**3  # GB
            self.gpu_memory_used.append(gpu_mem)
    
    def save(self, path: Union[str, Path]) -> None:
        """Salva mÃ©tricas em arquivo JSON."""
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # Converter para JSON serializable
        data = {
            'model_name': self.model_name,
            'dataset_path': self.dataset_path,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'total_epochs': self.total_epochs,
            'completed_epochs': self.completed_epochs,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'map50': self.map50,
            'map50_95': self.map50_95,
            'precision': self.precision,
            'recall': self.recall,
            'best_epoch': self.best_epoch,
            'best_map50': self.best_map50,
            'best_map50_95': self.best_map50_95,
            'gpu_memory_used': self.gpu_memory_used,
            'training_speed': self.training_speed,
            'duration_seconds': self.duration.total_seconds() if self.duration else None
        }
        
        with open(path, 'w') as f:
            json.dump(data, f, indent=2)
    
    @classmethod
    def load(cls, path: Union[str, Path]) -> "TrainingMetrics":
        """Carrega mÃ©tricas de arquivo JSON."""
        with open(path, 'r') as f:
            data = json.load(f)
        
        # Converter timestamps
        if data['start_time']:
            data['start_time'] = datetime.fromisoformat(data['start_time'])
        if data['end_time']:
            data['end_time'] = datetime.fromisoformat(data['end_time'])
        
        return cls(**{k: v for k, v in data.items() if k != 'duration_seconds'})


class YOLOTrainer:
    """Trainer principal para modelos YOLO."""
    
    def __init__(
        self,
        config_obj: Optional[YOLOConfig] = None,
        callbacks: Optional[List[Callable]] = None
    ):
        """
        Args:
            config_obj: ConfiguraÃ§Ã£o YOLO
            callbacks: Callbacks customizados
        """
        self.config = config_obj or YOLOConfig()
        self.callbacks = callbacks or []
        self.model = None
        self.metrics = None
        self.is_training = False
        
        # Validar hardware
        self._validate_hardware()
    
    def _validate_hardware(self) -> None:
        """Valida hardware disponÃ­vel."""
        device = str(self.config.training.device)
        
        if device != 'cpu':
            if not torch.cuda.is_available():
                logger.warning("CUDA nÃ£o disponÃ­vel, usando CPU")
                self.config.training.device = 'cpu'
            else:
                # Otimizar batch size para GPU disponÃ­vel
                optimized_batch = optimize_batch_size(
                    model_name=self.config.training.model,
                    current_batch=self.config.training.batch,
                    device=device
                )
                
                if optimized_batch != self.config.training.batch:
                    logger.info(f"ðŸ“Š Batch size otimizado: {self.config.training.batch} â†’ {optimized_batch}")
                    self.config.training.batch = optimized_batch
    
    def prepare_dataset(
        self,
        data_path: Union[str, Path],
        output_path: Optional[Union[str, Path]] = None
    ) -> Path:
        """Prepara dataset para treinamento."""
        data_path = Path(data_path)
        
        # Verificar se jÃ¡ existe data.yaml
        data_yaml = data_path / 'data.yaml'
        
        if data_yaml.exists():
            logger.info(f"âœ… Dataset jÃ¡ preparado: {data_yaml}")
            return data_yaml
        
        # Criar data.yaml se necessÃ¡rio
        if output_path:
            output_path = Path(output_path)
            data_yaml = create_data_yaml(
                data_path=data_path,
                output_path=output_path,
                task_type=self.config.training.task_type
            )
        else:
            raise DatasetNotFoundError(f"data.yaml nÃ£o encontrado em {data_path}")
        
        return data_yaml
    
    def train(
        self,
        data_path: Union[str, Path],
        resume: bool = False,
        **overrides
    ) -> TrainingMetrics:
        """
        Executa treinamento.
        
        Args:
            data_path: Caminho do dataset (pasta com data.yaml)
            resume: Continuar treinamento anterior
            **overrides: Sobrescrever configuraÃ§Ãµes
            
        Returns:
            MÃ©tricas do treinamento
        """
        try:
            logger.info("ðŸš€ Iniciando treinamento YOLO")
            self._log_training_info()
            
            # Preparar dataset
            data_yaml = self.prepare_dataset(data_path)
            self.config.training.data = str(data_yaml)
            
            # Aplicar overrides
            for key, value in overrides.items():
                if hasattr(self.config.training, key):
                    setattr(self.config.training, key, value)
            
            # Carregar modelo
            self.model = YOLO(self.config.training.model)
            
            # Configurar mÃ©tricas
            self.metrics = TrainingMetrics(
                model_name=self.config.training.model,
                dataset_path=str(data_path),
                total_epochs=self.config.training.epochs
            )
            
            # Configurar callbacks
            self._setup_callbacks()
            
            # Argumentos de treinamento
            train_args = self.config.training.to_ultralytics_args()
            
            logger.info("ðŸ‹ï¸ Iniciando treinamento...")
            self.is_training = True
            
            # Treinar modelo
            results = self.model.train(**train_args)
            
            # Finalizar mÃ©tricas
            self.metrics.end_time = datetime.now()
            self.is_training = False
            
            logger.success("âœ… Treinamento concluÃ­do!")
            self._log_training_results()
            
            # Salvar mÃ©tricas
            metrics_path = Path(train_args['project']) / train_args.get('name', 'exp') / 'metrics.json'
            self.metrics.save(metrics_path)
            
            return self.metrics
            
        except Exception as e:
            self.is_training = False
            logger.error(f"âŒ Erro no treinamento: {str(e)}")
            raise TrainingError(f"Erro no treinamento: {str(e)}")
    
    def _setup_callbacks(self) -> None:
        """Configura callbacks de treinamento."""
        def on_train_epoch_end(trainer):
            """Callback executado ao final de cada Ã©poca."""
            if self.metrics:
                # Extrair mÃ©tricas do trainer
                metrics_dict = {}
                if hasattr(trainer, 'metrics') and trainer.metrics:
                    metrics_dict = trainer.metrics
                elif hasattr(trainer, 'validator') and trainer.validator:
                    if hasattr(trainer.validator, 'metrics'):
                        metrics_dict = trainer.validator.metrics
                
                self.metrics.update_epoch(trainer.epoch, metrics_dict)
                
                # Log progresso
                progress = self.metrics.progress * 100
                eta_str = f"ETA: {self.metrics.eta}" if self.metrics.eta else "ETA: N/A"
                
                logger.info(f"ðŸ“Š Ã‰poca {trainer.epoch + 1}/{self.metrics.total_epochs} "
                          f"({progress:.1f}%) - {eta_str}")
                
                if self.metrics.map50:
                    logger.info(f"ðŸŽ¯ mAP50: {self.metrics.map50[-1]:.3f} "
                              f"(melhor: {self.metrics.best_map50:.3f} @ Ã©poca {self.metrics.best_epoch + 1})")
        
        # Adicionar callback personalizado
        if hasattr(self.model, 'add_callback'):
            self.model.add_callback('on_train_epoch_end', on_train_epoch_end)
    
    def _log_training_info(self) -> None:
        """Log informaÃ§Ãµes do treinamento."""
        tc = self.config.training
        
        logger.info("ðŸ“‹ CONFIGURAÃ‡ÃƒO DE TREINAMENTO:")
        logger.info(f"  â€¢ Modelo: {tc.model}")
        logger.info(f"  â€¢ Tarefa: {tc.task_type}")
        logger.info(f"  â€¢ Ã‰pocas: {tc.epochs}")
        logger.info(f"  â€¢ Batch size: {tc.batch}")
        logger.info(f"  â€¢ Imagem: {tc.imgsz}px")
        logger.info(f"  â€¢ Dispositivo: {tc.device}")
        logger.info(f"  â€¢ Workers: {tc.workers}")
        logger.info(f"  â€¢ Augmentations: {'âœ…' if tc.augmentation.enabled else 'âŒ'}")
        
        # Estimar tempo
        if tc.data:
            try:
                with open(tc.data, 'r') as f:
                    data_config = yaml.safe_load(f)
                
                # Contar imagens de treino (estimativa)
                train_path = Path(data_config['path']) / data_config['train']
                if train_path.exists():
                    train_images = len(list(train_path.glob('*.jpg'))) + len(list(train_path.glob('*.png')))
                    time_estimate = tc.estimate_training_time(train_images)
                    logger.info(f"â±ï¸ Tempo estimado: {time_estimate['estimated_completion']}")
            except:
                pass
    
    def _log_training_results(self) -> None:
        """Log resultados do treinamento."""
        if not self.metrics:
            return
            
        logger.info("ðŸŽ‰ RESULTADOS DO TREINAMENTO:")
        logger.info(f"  â€¢ DuraÃ§Ã£o: {self.metrics.duration}")
        logger.info(f"  â€¢ Ã‰pocas completadas: {self.metrics.completed_epochs}/{self.metrics.total_epochs}")
        logger.info(f"  â€¢ Melhor mAP50: {self.metrics.best_map50:.3f} (Ã©poca {self.metrics.best_epoch + 1})")
        logger.info(f"  â€¢ mAP50-95: {self.metrics.best_map50_95:.3f}")
        
        if self.metrics.gpu_memory_used:
            max_gpu_mem = max(self.metrics.gpu_memory_used)
            logger.info(f"  â€¢ GPU Memory pico: {max_gpu_mem:.1f}GB")
    
    def resume_training(
        self,
        checkpoint_path: Union[str, Path],
        **overrides
    ) -> TrainingMetrics:
        """Resume treinamento de checkpoint."""
        logger.info(f"ðŸ”„ Resumindo treinamento: {checkpoint_path}")
        
        # Carregar modelo do checkpoint
        self.model = YOLO(checkpoint_path)
        
        # Continuar treinamento
        return self.train(resume=True, **overrides)
    
    def validate(
        self,
        data_path: Optional[Union[str, Path]] = None,
        **kwargs
    ) -> Dict[str, float]:
        """Valida modelo treinado."""
        if not self.model:
            raise ModelNotFoundError("Modelo nÃ£o treinado")
        
        logger.info("ðŸ” Validando modelo...")
        
        if data_path:
            data_yaml = self.prepare_dataset(data_path)
            kwargs['data'] = str(data_yaml)
        
        results = self.model.val(**kwargs)
        
        logger.success("âœ… ValidaÃ§Ã£o concluÃ­da")
        return results.results_dict if hasattr(results, 'results_dict') else {}
    
    def export_model(
        self,
        format: str = 'onnx',
        output_dir: Optional[Union[str, Path]] = None,
        **kwargs
    ) -> Path:
        """Exporta modelo treinado."""
        if not self.model:
            raise ModelNotFoundError("Modelo nÃ£o treinado")
        
        logger.info(f"ðŸ“¦ Exportando modelo para {format.upper()}...")
        
        exported_path = self.model.export(format=format, **kwargs)
        
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            exported_path = Path(exported_path)
            final_path = output_dir / exported_path.name
            exported_path.rename(final_path)
            exported_path = final_path
        
        logger.success(f"âœ… Modelo exportado: {exported_path}")
        return Path(exported_path)

# ğŸ¯ Datalid 3.0 - Sistema de DetecÃ§Ã£o de Datas de Validade

## â­ FOCO: SEGMENTAÃ‡ÃƒO POLIGONAL (DetecÃ§Ã£o de Contornos Precisos)

Este projeto utiliza **YOLOv8 Segmentation** para detectar datas de validade com contornos poligonais precisos, proporcionando melhor acurÃ¡cia para OCR subsequente.

## ğŸ¨ Por que SegmentaÃ§Ã£o?

- âœ… **Maior precisÃ£o**: Contornos poligonais precisos ao invÃ©s de bounding boxes
- âœ… **Melhor para OCR**: MÃ¡scaras precisas facilitam extraÃ§Ã£o de texto
- âœ… **VersÃ£o final do TCC**: Foco principal do projeto
- ğŸ“¦ **DetecÃ§Ã£o bbox**: Mantida apenas para comparaÃ§Ã£o

## ğŸš€ CaracterÃ­sticas

- ğŸ¯ **DetecÃ§Ã£o**: YOLOv8 com segmentaÃ§Ã£o de instÃ¢ncias (poligonal)
- ğŸ” **OCR**: Reconhecimento de texto (a implementar)
- ğŸ“Š **MÃ©tricas**: Tracking completo de treinamento
- ğŸ³ **Deploy**: ContainerizaÃ§Ã£o com Docker

## ğŸ“ Estrutura do Projeto

```
datalid3.0/
â”œâ”€â”€ src/                    # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ core/              # ConfiguraÃ§Ãµes, constantes, exceÃ§Ãµes
â”‚   â”œâ”€â”€ data/              # Processamento e carregamento de dados
â”‚   â”œâ”€â”€ yolo/              # Modelos YOLO (segmentaÃ§Ã£o + detecÃ§Ã£o)
â”‚   â”œâ”€â”€ ocr/               # Reconhecimento de texto (a implementar)
â”‚   â”œâ”€â”€ api/               # API REST (a implementar)
â”‚   â””â”€â”€ utils/             # UtilitÃ¡rios gerais
â”œâ”€â”€ config/                # ConfiguraÃ§Ãµes de treinamento
â”‚   â””â”€â”€ yolo/
â”‚       â”œâ”€â”€ segmentation/  # â­ SegmentaÃ§Ã£o (PRINCIPAL)
â”‚       â””â”€â”€ bbox/          # DetecÃ§Ã£o bbox (alternativo)
â”œâ”€â”€ data/                  # Dados (nÃ£o versionado)
â”‚   â”œâ”€â”€ raw/              # Dados originais
â”‚   â””â”€â”€ processed/        
â”‚       â”œâ”€â”€ v1_segment/   # â­ Dataset segmentaÃ§Ã£o (PRINCIPAL)
â”‚       â””â”€â”€ v1_detect/    # Dataset detecÃ§Ã£o (alternativo)
â”œâ”€â”€ scripts/               # Scripts utilitÃ¡rios
â”œâ”€â”€ experiments/           # Logs de treinamento
â””â”€â”€ Makefile              # Comandos automatizados
```

## âš¡ Quick Start

### 1. InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone <repo-url>
cd datalid3.0

# Instalar dependÃªncias
make install-all

# Testar ambiente
make test-cuda
make validate-env
```

### 2. Processar Dados RAW - SEGMENTAÃ‡ÃƒO â­

**OpÃ§Ã£o 1: Processamento RÃ¡pido (70/20/10) - SEGMENTAÃ‡ÃƒO**
```bash
make quick-process
```

**OpÃ§Ã£o 2: Processamento Customizado - SEGMENTAÃ‡ÃƒO**
```bash
# Exemplo: 80% treino, 15% validaÃ§Ã£o, 5% teste
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/v1_segment \
    --train-split 0.8 \
    --val-split 0.15 \
    --test-split 0.05 \
    --task-type segment \
    --validate-raw \
    --validate-output
```

**OpÃ§Ã£o 3: Processar DETECÃ‡ÃƒO (alternativo)**
```bash
make quick-process-detect
```

### 3. Validar Dataset

```bash
# ValidaÃ§Ã£o completa - SEGMENTAÃ‡ÃƒO
python scripts/validate_dataset.py data/processed/v1_segment --detailed

# ValidaÃ§Ã£o - DETECÃ‡ÃƒO
python scripts/validate_dataset.py data/processed/v1_detect --detailed
```

### 4. Treinar Modelos - SEGMENTAÃ‡ÃƒO â­

**Teste RÃ¡pido (10 Ã©pocas)**
```bash
make train-quick
```

**Treinamento Desenvolvimento**
```bash
make train-dev
```

**Treinamentos Finais TCC**
```bash
# YOLOv8n-seg (rÃ¡pido)
make train-final-nano

# YOLOv8s-seg (recomendado) â­
make train-final-small

# YOLOv8m-seg (melhor qualidade)
make train-final-medium
```

**Comparar Todos os Modelos SEGMENTAÃ‡ÃƒO**
```bash
make train-compare-all
```

### 5. Treinar Modelos - DETECÃ‡ÃƒO (Alternativo)

```bash
# Teste rÃ¡pido detecÃ§Ã£o
make train-quick-detect

# Treinamento final detecÃ§Ã£o
make train-final-detect-small
```

## ğŸ“Š Workflow Completo TCC

```bash
# Workflow completo SEGMENTAÃ‡ÃƒO (recomendado) â­
make workflow-tcc INPUT=data/raw/meu_dataset

# Workflow completo DETECÃ‡ÃƒO (alternativo)
make workflow-tcc-detect INPUT=data/raw/meu_dataset
```

## ğŸ›ï¸ Comandos DisponÃ­veis

### Processamento de Dados
- `make process-data INPUT=<path>` - Processar dados (SEGMENTAÃ‡ÃƒO) â­
- `make process-detect INPUT=<path>` - Processar dados (DETECÃ‡ÃƒO)
- `make quick-process` - Processamento rÃ¡pido (SEGMENTAÃ‡ÃƒO) â­
- `make validate-data` - Validar datasets processados

### Treinamento - SEGMENTAÃ‡ÃƒO â­
- `make train-quick` - Teste rÃ¡pido (10 Ã©pocas)
- `make train-dev` - Desenvolvimento
- `make train-nano` - YOLOv8n-seg
- `make train-small` - YOLOv8s-seg (recomendado)
- `make train-medium` - YOLOv8m-seg
- `make train-final-nano` - Final TCC nano
- `make train-final-small` - Final TCC small â­
- `make train-final-medium` - Final TCC medium
- `make train-compare-all` - Comparar modelos

### Treinamento - DETECÃ‡ÃƒO (Alternativo)
- `make train-quick-detect` - Teste rÃ¡pido detecÃ§Ã£o
- `make train-detect-nano` - YOLOv8n bbox
- `make train-detect-small` - YOLOv8s bbox
- `make train-final-detect-small` - Final TCC detecÃ§Ã£o
- `make train-compare-detect` - Comparar modelos detecÃ§Ã£o

### AnÃ¡lise e ComparaÃ§Ã£o
- `make tensorboard` - Visualizar mÃ©tricas em tempo real
- `make compare-models` - ğŸ“Š Comparar todos os modelos treinados
- `make compare-segments` - ğŸ“Š Comparar apenas modelos de segmentaÃ§Ã£o
- `make compare-detects` - ğŸ“Š Comparar apenas modelos de detecÃ§Ã£o
- `make analyze-errors` - ğŸ” Analisar erros de um modelo (requer MODEL= e DATA=)
- `make analyze-best-model` - ğŸ” Analisar automaticamente o Ãºltimo modelo treinado
- `make list-experiments` - Listar experimentos

### UtilitÃ¡rios
- `make help` - Listar todos os comandos
- `make help-new-system` - Ajuda do sistema novo
- `make configure` - Configurador interativo
- `make list-presets` - Listar presets disponÃ­veis

## ğŸ“ˆ Monitoramento

```bash
# Iniciar TensorBoard
make tensorboard
# Acessar: http://localhost:6006

# Listar experimentos concluÃ­dos
make list-completed

# Comparar experimentos
make compare-final
```

## ğŸ¯ Datalid 3.0 - Sistema de DetecÃ§Ã£o de Datas de Validade

Sistema inteligente para detecÃ§Ã£o e extraÃ§Ã£o de datas de validade em produtos usando YOLOv8 e OCR.

## ğŸš€ Principais Funcionalidades

- âœ… **Processamento FlexÃ­vel**: Converte dados RAW com splits customizÃ¡veis (train/val/test)
- ğŸ¤– **MÃºltiplos Modelos**: Suporte para YOLOv8n, YOLOv8s, YOLOv8m (detecÃ§Ã£o e segmentaÃ§Ã£o)
- ğŸ” **ValidaÃ§Ã£o Completa**: ValidaÃ§Ã£o automÃ¡tica de datasets e integridade de dados
- ğŸ“Š **AnÃ¡lise Detalhada**: MÃ©tricas, visualizaÃ§Ãµes e comparaÃ§Ã£o de modelos
- ğŸŒ **API REST**: Interface para integraÃ§Ã£o com outros sistemas
- ğŸ³ **Deploy**: ContainerizaÃ§Ã£o com Docker

## ğŸ“ Estrutura do Projeto

```
datalid3.0/
â”œâ”€â”€ src/                    # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ core/              # ConfiguraÃ§Ãµes, constantes, exceÃ§Ãµes
â”‚   â”œâ”€â”€ data/              # Processamento e carregamento de dados
â”‚   â”œâ”€â”€ yolo/              # Modelos YOLO (a implementar)
â”‚   â”œâ”€â”€ ocr/               # Reconhecimento de texto (a implementar)
â”‚   â”œâ”€â”€ api/               # API REST (a implementar)
â”‚   â””â”€â”€ utils/             # UtilitÃ¡rios gerais (a implementar)
â”œâ”€â”€ config/                # ConfiguraÃ§Ãµes de treinamento
â”‚   â””â”€â”€ yolo/
â”‚       â”œâ”€â”€ bbox/          # DetecÃ§Ã£o (bounding boxes)
â”‚       â””â”€â”€ segmentation/  # SegmentaÃ§Ã£o
â”œâ”€â”€ data/                  # Dados (nÃ£o versionado)
â”‚   â”œâ”€â”€ raw/              # Dados originais
â”‚   â””â”€â”€ processed/        # Dados processados
â”œâ”€â”€ scripts/               # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ process_raw_data.py    # Processar dados RAW
â”‚   â”œâ”€â”€ validate_dataset.py    # Validar datasets
â”‚   â””â”€â”€ test_cuda.py          # Testar GPU/CUDA
â”œâ”€â”€ experiments/           # Logs de treinamento (nÃ£o versionado)
â””â”€â”€ Makefile              # Comandos automatizados
```

## âš¡ Quick Start

### 1. InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone <repo-url>
cd datalid3.0

# Instalar dependÃªncias
make install-all

# Testar ambiente
make test-cuda
make validate-env
```

### 2. Processar Dados RAW

**OpÃ§Ã£o 1: Processamento RÃ¡pido (70/20/10)**
```bash
make quick-process
```

**OpÃ§Ã£o 2: Processamento Customizado**
```bash
# Exemplo: 80% treino, 15% validaÃ§Ã£o, 5% teste
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/custom \
    --train-split 0.8 \
    --val-split 0.15 \
    --test-split 0.05 \
    --task-type detect \
    --validate-raw \
    --validate-output
```

**OpÃ§Ã£o 3: Usar Presets**
```bash
# Preset balanceado (60/20/20)
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/balanced \
    --preset balanced

# Preset para pesquisa (80/10/10)
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/research \
    --preset research
```

### 3. Validar Dataset

```bash
# ValidaÃ§Ã£o completa
python scripts/validate_dataset.py data/processed/detection --detailed

# Salvar relatÃ³rio
python scripts/validate_dataset.py data/processed/detection \
    --detailed \
    --output-report validation_report.json
```

### 4. Treinar Modelos

```bash
# Modelo rÃ¡pido (baseline)
make train-nano

# Modelo recomendado
make train-small

# Modelo de alta qualidade
make train-medium

# SegmentaÃ§Ã£o
make train-seg-small
```

### 5. Monitorar Treinamento

```bash
# TensorBoard
make tensorboard
# Acesse: http://localhost:6006
```

## ğŸ”§ ConfiguraÃ§Ãµes de Splits

### Presets DisponÃ­veis

| Preset | Treino | ValidaÃ§Ã£o | Teste | Uso Recomendado |
|--------|--------|-----------|-------|----------------|
| `balanced` | 60% | 20% | 20% | Desenvolvimento balanceado |
| `research` | 80% | 10% | 10% | Pesquisa acadÃªmica (TCC) |
| `production` | 70% | 30% | 0% | Deploy em produÃ§Ã£o |
| `quick_test` | 50% | 25% | 25% | Testes rÃ¡pidos |

### Splits Customizados

```python
# Exemplo: dataset pequeno com mais validaÃ§Ã£o
--train-split 0.6 --val-split 0.3 --test-split 0.1

# Exemplo: sem conjunto de teste
--train-split 0.8 --val-split 0.2 --test-split 0.0

# Exemplo: igual distribuiÃ§Ã£o
--train-split 0.33 --val-split 0.33 --test-split 0.34
```

## ğŸ¯ Fluxo de Trabalho Completo

### Para Desenvolvimento
```bash
# 1. Setup inicial
make setup

# 2. Processar dados
make quick-process

# 3. Treinar modelo baseline
make train-small

# 4. Monitorar
make tensorboard
```

### Para Pesquisa (TCC)
```bash
# 1. Setup e processamento para pesquisa
make setup
make research-process

# 2. Treinar mÃºltiplos modelos
make train-final-nano    # YOLOv8n-seg (rÃ¡pido)
make train-final-small   # YOLOv8s-seg (balanceado)
make train-final-medium  # YOLOv8m-seg (melhor qualidade)

# 3. AnÃ¡lise e comparaÃ§Ã£o completa
make compare-models      # Comparar todos os modelos
make analyze-best-model  # Analisar erros do melhor modelo

# 4. Revisar resultados
# - Abrir outputs/model_comparison/comparison_report.md
# - Verificar outputs/error_analysis/*/visualizations/
```

### Para ProduÃ§Ã£o
```bash
# 1. Processamento otimizado
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/production \
    --preset production

# 2. Treinar modelo final
make train-small

# 3. Deploy
make build-docker
make run-docker
```

## ğŸ“Š ValidaÃ§Ã£o de Dados

### ValidaÃ§Ã£o AutomÃ¡tica
O sistema inclui validaÃ§Ã£o completa que verifica:

- âœ… Estrutura de diretÃ³rios
- âœ… Integridade de imagens
- âœ… Formato de labels YOLO
- âœ… CorrespondÃªncia imagem-label
- âœ… ConsistÃªncia do data.yaml
- âœ… Coordenadas normalizadas

### Tipos de ValidaÃ§Ã£o

```bash
# ValidaÃ§Ã£o bÃ¡sica
python scripts/validate_dataset.py data/processed/detection

# ValidaÃ§Ã£o detalhada
python scripts/validate_dataset.py data/processed/detection --detailed

# ValidaÃ§Ã£o com relatÃ³rio
python scripts/validate_dataset.py data/processed/detection \
    --detailed \
    --output-report report.json
```

## ğŸ¤– Modelos Suportados

### DetecÃ§Ã£o (Bounding Boxes)
- **YOLOv8n**: Mais rÃ¡pido, menor precisÃ£o (~2-3h treino)
- **YOLOv8s**: EquilÃ­brio, recomendado (~4-5h treino) 
- **YOLOv8m**: Melhor precisÃ£o, mais lento (~10-12h treino)

### SegmentaÃ§Ã£o (MÃ¡scaras)
- **YOLOv8n-seg**: SegmentaÃ§Ã£o rÃ¡pida
- **YOLOv8s-seg**: SegmentaÃ§Ã£o equilibrada
- **YOLOv8m-seg**: SegmentaÃ§Ã£o de alta qualidade

## ğŸ” Comandos Ãšteis

### VerificaÃ§Ã£o do Sistema
```bash
make info          # InformaÃ§Ãµes do projeto
make status         # Status atual (dados, experimentos)
make test-cuda      # Testar GPU/CUDA
```

### Limpeza
```bash
make clean          # Arquivos temporÃ¡rios
make clean-data     # Dados processados
make clean-models   # Modelos treinados
make clean-all      # Limpeza completa
```

### Ajuda
```bash
make help           # Lista todos os comandos
make                # Mesmo que make help
```

## ğŸ¨ Exemplo de Uso PrÃ¡tico

```bash
# 1. Instalar e configurar
make install-all
make test-cuda

# 2. Colocar dados RAW em data/raw/

# 3. Processar com split customizado para TCC
python scripts/process_raw_data.py \
    --raw-path data/raw \
    --output-path data/processed/tcc_dataset \
    --train-split 0.75 \
    --val-split 0.15 \
    --test-split 0.10 \
    --task-type detect \
    --validate-raw \
    --validate-output

# 4. Validar resultado
python scripts/validate_dataset.py data/processed/tcc_dataset --detailed

# 5. Atualizar config/yolo/bbox/data.yaml se necessÃ¡rio

# 6. Treinar modelo
make train-small

# 7. Monitorar resultados
make tensorboard
```

## ï¿½ AnÃ¡lise e ComparaÃ§Ã£o de Modelos

O DATALID 3.0 inclui ferramentas poderosas para anÃ¡lise de erros e comparaÃ§Ã£o de modelos.

### ğŸ“Š ComparaÃ§Ã£o de Modelos

Compare mÃºltiplos modelos treinados e gere relatÃ³rios detalhados:

```bash
# Comparar todos os modelos
make compare-models

# Comparar apenas modelos de segmentaÃ§Ã£o
make compare-segments

# Comparar apenas modelos de detecÃ§Ã£o
make compare-detects

# ComparaÃ§Ã£o customizada
python scripts/compare_models.py \
    --models nano-seg-10e small-seg-10e \
    --rank-by map50_95
```

**SaÃ­das geradas:**
- ğŸ“ `comparison_report.md` - RelatÃ³rio completo em Markdown
- ğŸ“Š `model_comparison.csv` - Tabela para Excel
- ğŸ¨ 7 grÃ¡ficos comparativos em `visualizations/`

### ğŸ” AnÃ¡lise de Erros

Analise erros de prediÃ§Ã£o (FP, FN, Misclassifications):

```bash
# Analisar modelo especÃ­fico
make analyze-errors \
    MODEL=experiments/nano-seg-10e/weights/best.pt \
    DATA=data/processed/v1_segment

# Analisar Ãºltimo modelo treinado automaticamente
make analyze-best-model

# AnÃ¡lise customizada
python scripts/error_analysis.py \
    --model path/to/model.pt \
    --data path/to/dataset \
    --conf-threshold 0.5 \
    --max-images 100
```

**SaÃ­das geradas:**
- ğŸ“‹ `error_analysis.json` - EstatÃ­sticas completas
- ğŸ“Š `class_metrics.csv` - MÃ©tricas por classe
- ğŸ¨ 4 grÃ¡ficos de anÃ¡lise em `visualizations/`
- ğŸ–¼ï¸ Imagens com erros anotados em `errors/`

### ğŸ“š DocumentaÃ§Ã£o Detalhada

Para mais informaÃ§Ãµes sobre anÃ¡lise:
- ğŸ“– **Guia Completo**: `docs/GUIA_ANALISE_MODELOS.md`
- âš¡ **ReferÃªncia RÃ¡pida**: `docs/ANALISE_QUICK_REFERENCE.md`
- ğŸ“Š **Exemplos de Outputs**: `docs/EXEMPLOS_OUTPUTS.md`

## ï¿½ğŸ“ Notas Importantes

- **Dados RAW**: Mantenha sempre uma cÃ³pia dos dados originais em `data/raw/`
- **Splits**: A soma deve ser exatamente 1.0 (ex: 0.7 + 0.2 + 0.1 = 1.0)
- **GPU**: Sistema otimizado para GTX 1660 Super (6GB VRAM)
- **Backup**: Experimentos importantes sÃ£o salvos automaticamente
- **Reprodutibilidade**: Use seeds fixas para resultados consistentes

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**Desenvolvido para o TCC - Sistema de DetecÃ§Ã£o de Datas de Validade**

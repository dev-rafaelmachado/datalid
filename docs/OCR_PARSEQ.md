# üî§ PARSeq OCR Engine

## Vis√£o Geral

PARSeq (Permutation Auto-regressive Sequence) √© um modelo de OCR baseado em Transformers desenvolvido para reconhecimento de texto em cena. Ele usa uma arquitetura de auto-regress√£o permutacional que permite maior efici√™ncia e precis√£o.

### Vers√£o TINE (Tiny Efficient)

Este projeto utiliza a vers√£o **TINE** do PARSeq, que √© otimizada para:
- **Tamanho reduzido**: ~20MB (vs ~60MB da vers√£o base)
- **Infer√™ncia r√°pida**: Ideal para processamento em tempo real
- **Boa precis√£o**: Mant√©m alta qualidade de reconhecimento
- **Baixo consumo de mem√≥ria**: Adequado para dispositivos com recursos limitados

## Caracter√≠sticas

- **Arquitetura**: Transformer-based com Vision Transformer (ViT) como encoder
- **Treinamento**: Pr√©-treinado em m√∫ltiplos datasets de reconhecimento de texto
- **Vers√£o TINE**: Vers√£o otimizada e mais leve (Tiny Efficient)
- **Carregamento**: Via torch.hub do reposit√≥rio oficial (baudm/parseq)
- **Vantagens**:
  - Suporte a texto em m√∫ltiplas orienta√ß√µes
  - Robusto a varia√ß√µes de fonte e estilo
  - Boa performance em texto impresso
  - Modelo compacto (vers√£o tiny)
  - Sem necessidade de instala√ß√£o adicional (apenas torch)

## Instala√ß√£o

### Requisitos

```bash
pip install torch torchvision Pillow
```

### Carregamento do Modelo

O PARSeq √© carregado automaticamente via `torch.hub` do reposit√≥rio oficial:

```bash
# O modelo ser√° baixado automaticamente na primeira execu√ß√£o
python -c "import torch; model = torch.hub.load('baudm/parseq', 'parseq-tiny', pretrained=True)"
```

## Configura√ß√£o

### Arquivo de Configura√ß√£o: `config/ocr/parseq.yaml`

```yaml
# PARSeq OCR espec√≠fico
engine: parseq

# Modelo
model_name: 'parseq-tiny'  # parseq-tiny, parseq, parseq-large

# Device
device: 'cuda'  # ou 'cpu'

# Configura√ß√£o de imagem
img_height: 32
img_width: 128
max_length: 25

# Thresholds
confidence_threshold: 0.7

# Preprocessing
preprocessing: ppro-parseq
```

### Modelos Dispon√≠veis

**IMPORTANTE**: Para dataset com texto **multi-linha** (2+ linhas), escolha `parseq` ou `parseq_patch16_224`!

1. **parseq_tiny** (‚ö° r√°pido)
   - Menor e mais r√°pido
   - **Apenas para texto de 1 linha simples**
   - ‚ùå **N√ÉO recomendado para multi-linha**
   - Tamanho: ~20MB
   - Velocidade: 10-20ms/imagem (GPU)

2. **parseq** (‚≠ê base - **RECOMENDADO para multi-linha**)
   - Balanceado entre tamanho e precis√£o
   - ‚úÖ **Muito bom para texto multi-linha**
   - ‚úÖ **Melhor custo-benef√≠cio**
   - Tamanho: ~60MB
   - Velocidade: 30-50ms/imagem (GPU)

3. **parseq_patch16_224** (üèÜ large)
   - Maior precis√£o
   - ‚úÖ **Excelente para texto multi-linha complexo**
   - Mais lento, mas mais preciso
   - Tamanho: ~100MB
   - Velocidade: 50-100ms/imagem (GPU)

## Pr√©-processamento

### Configura√ß√£o Otimizada: `config/preprocessing/ppro-parseq.yaml`

O PARSeq funciona melhor com:

1. **Imagens em Grayscale**: Reduz complexidade
2. **Dimens√µes fixas**: 32px de altura, at√© 128px de largura
3. **CLAHE leve**: Melhora contraste
4. **Denoising suave**: Remove ru√≠do sem perder detalhes
5. **Padding centralizado**: Garante dimens√µes corretas

```yaml
steps:
  - name: grayscale
    enabled: true
  - name: resize
    enabled: true
    params:
      height: 32
      width: 128
      keep_aspect_ratio: true
  - name: clahe
    enabled: true
    params:
      clip_limit: 2.0
  - name: denoise
    enabled: true
    params:
      method: fastNlMeans
      h: 5
  - name: padding
    enabled: true
    params:
      target_height: 32
      target_width: 128
```

## Uso

### 1. Via Makefile

```bash
# Testar PARSeq individualmente
make ocr-test ENGINE=parseq

# Testar com pr√©-processamento espec√≠fico
make ocr-test ENGINE=parseq PREP=ppro-parseq

# Comparar com outros engines
make ocr-compare ENGINE=parseq

# Benchmark completo (inclui PARSeq)
make ocr-benchmark
```

### 2. Via Python

```python
from src.ocr.engines.parseq import PARSeqEngine
from src.ocr.config import load_ocr_config
import cv2

# Carregar configura√ß√£o
config = load_ocr_config('config/ocr/parseq.yaml')

# Inicializar engine
engine = PARSeqEngine(config)
engine.initialize()

# Ler imagem
image = cv2.imread('path/to/image.jpg')

# Extrair texto
text, confidence = engine.extract_text(image)

print(f"Texto: {text}")
print(f"Confian√ßa: {confidence:.2f}")
```

### 3. Via Script de Benchmark

```bash
# Testar apenas PARSeq
python scripts/ocr/benchmark_ocrs.py \
    --engine parseq \
    --preprocessing medium \
    --output outputs/ocr_benchmarks/parseq_test

# Comparar todos os engines (incluindo PARSeq)
python scripts/ocr/benchmark_ocrs.py \
    --engines tesseract easyocr paddleocr trocr parseq \
    --output outputs/ocr_benchmarks/comparison
```

## Performance

### Caracter√≠sticas de Performance

- **Velocidade**: R√°pida (especialmente vers√£o tiny)
  - GPU: ~20-50ms por imagem
  - CPU: ~100-200ms por imagem

- **Mem√≥ria**: Eficiente
  - parseq-tiny: ~200MB VRAM
  - parseq: ~500MB VRAM
  - parseq-large: ~1GB VRAM

- **Precis√£o**: Alta para texto impresso
  - Melhor em: Texto claro, fonte padr√£o
  - Razo√°vel em: Texto com ru√≠do, baixa qualidade
  - Limitado em: Texto manuscrito, muito distorcido

### Compara√ß√£o com Outros Engines

| Engine | Velocidade | Precis√£o | Mem√≥ria | GPU |
|--------|-----------|----------|---------|-----|
| Tesseract | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå |
| EasyOCR | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ |
| PaddleOCR | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ |
| TrOCR | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚úÖ |
| **PARSeq** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ |

## Casos de Uso

### Quando Usar PARSeq

‚úÖ **Recomendado para:**
- Texto impresso em datas de validade
- Necessidade de processamento r√°pido
- Ambientes com GPU dispon√≠vel
- Texto horizontal ou levemente inclinado
- Cen√°rios com recursos limitados (vers√£o tiny)

‚ö†Ô∏è **Considerar alternativas para:**
- Texto manuscrito
- Texto muito distorcido ou com perspectiva extrema
- M√∫ltiplas linhas de texto complexo
- Idiomas n√£o latinos (considerar PaddleOCR)

### Combina√ß√£o com YOLO

PARSeq √© excelente para o pipeline de detec√ß√£o de datas de validade:

1. **YOLO** detecta a regi√£o da data
2. **Segmenta√ß√£o** isola o texto
3. **PARSeq** reconhece os caracteres

```python
from src.pipeline.full_pipeline import FullPipeline

# Pipeline completo
pipeline = FullPipeline(
    yolo_model='experiments/yolov8s_seg_final/weights/best.pt',
    ocr_engine='parseq',
    ocr_config='config/ocr/parseq.yaml'
)

# Processar imagem
result = pipeline.process_image('product.jpg')
print(f"Data detectada: {result['date']}")
```

## Troubleshooting

### Problemas Comuns

**1. Erro ao carregar modelo via torch.hub**
```bash
# Solu√ß√£o: Verificar conex√£o com internet
# Ou baixar manualmente
git clone https://github.com/baudm/parseq.git
```

**2. CUDA Out of Memory**
```yaml
# Solu√ß√£o: Usar CPU ou modelo menor
device: 'cpu'
model_name: 'parseq-tiny'
```

**3. Resultados inconsistentes**
```bash
# Solu√ß√£o: Ajustar pr√©-processamento
make ocr-test ENGINE=parseq PREP=ppro-parseq
```

**4. Texto n√£o detectado**
- Verificar se a imagem tem texto vis√≠vel
- Testar com pr√©-processamento mais agressivo
- Verificar dimens√µes da imagem (muito pequena ou grande)

## Refer√™ncias

- **Paper**: [Scene Text Recognition with Permuted Autoregressive Sequence Models](https://arxiv.org/abs/2207.06966)
- **Reposit√≥rio**: [baudm/parseq](https://github.com/baudm/parseq)
- **Hugging Face**: Modelos tamb√©m dispon√≠veis no Hub

## Changelog

### v1.0 (2025-10-19)
- ‚úÖ Implementa√ß√£o inicial do PARSeq Engine
- ‚úÖ Suporte √† vers√£o TinE (Tiny Efficient)
- ‚úÖ Configura√ß√µes otimizadas de pr√©-processamento
- ‚úÖ Integra√ß√£o com pipeline de benchmark
- ‚úÖ Documenta√ß√£o completa

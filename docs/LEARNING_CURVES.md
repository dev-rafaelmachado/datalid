# ğŸ“Š AnÃ¡lise de Curvas de Aprendizado

## ğŸ¯ Objetivo

Este documento descreve o sistema de anÃ¡lise de curvas de aprendizado implementado no projeto Datalid 3.0. O objetivo Ã© validar se os modelos YOLO estÃ£o realmente aprendendo ou apenas memorizando (overfitting), treinando-os com diferentes fraÃ§Ãµes dos dados de treinamento (25%, 50%, 75%, 100%).

## ğŸ” MotivaÃ§Ã£o

**QuestÃµes-chave que este sistema responde:**

1. **Os modelos estÃ£o realmente aprendendo?**
   - Se o mAP aumenta consistentemente com mais dados â†’ Aprendizado genuÃ­no âœ…
   - Se o mAP nÃ£o muda significativamente â†’ PossÃ­vel overfitting ou dados redundantes âš ï¸

2. **Qual fraÃ§Ã£o de dados Ã© suficiente?**
   - Podemos obter resultados similares com menos dados?
   - Onde estÃ¡ o ponto de rendimento decrescente?

3. **Como diferentes modelos se comportam?**
   - Nano vs Small vs Medium: qual aproveita melhor os dados?
   - Modelos maiores precisam de mais dados para brilhar?

## ğŸ—ï¸ Arquitetura do Sistema

### 1. Processamento de Dados com FraÃ§Ãµes

```
data/processed/v1_segment (base completa)
    â†“
scripts/process_with_fraction.py
    â†“
data/processed/fractions/
    â”œâ”€â”€ fraction_0.25/  (25% dos dados de treino)
    â”œâ”€â”€ fraction_0.50/  (50% dos dados de treino)
    â”œâ”€â”€ fraction_0.75/  (75% dos dados de treino)
    â””â”€â”€ fraction_1.0/   (100% dos dados de treino)
```

**CaracterÃ­sticas:**
- ValidaÃ§Ã£o e teste permanecem SEMPRE os mesmos (para comparaÃ§Ã£o justa)
- Apenas o conjunto de treino Ã© fracionado
- Seed fixo (42) para reprodutibilidade
- Amostragem aleatÃ³ria estratificada

### 2. ConfiguraÃ§Ãµes de Treinamento

Arquivos YAML padronizados garantem hiperparÃ¢metros consistentes:

```
config/yolo/learning_curves/
    â”œâ”€â”€ yolov8n-seg-fraction.yaml  (Nano)
    â”œâ”€â”€ yolov8s-seg-fraction.yaml  (Small)
    â””â”€â”€ yolov8m-seg-fraction.yaml  (Medium)
```

**HiperparÃ¢metros consistentes:**
- Ã‰pocas: 100
- Batch size: adaptado por modelo (Nano: 32, Small: 16, Medium: 8)
- Learning rate: 0.01
- Augmentation: medium (consistente)
- Early stopping: patience 20

### 3. Experimentos Organizados

```
experiments/
    â”œâ”€â”€ learning_curve_nano_0.25/
    â”œâ”€â”€ learning_curve_nano_0.50/
    â”œâ”€â”€ learning_curve_nano_0.75/
    â”œâ”€â”€ learning_curve_nano_1.0/
    â”œâ”€â”€ learning_curve_small_0.25/
    â”œâ”€â”€ learning_curve_small_0.50/
    â””â”€â”€ ... (12 experimentos no total)
```

### 4. AnÃ¡lise e VisualizaÃ§Ã£o

Script `compare_learning_curves.py` gera:

1. **GrÃ¡ficos de Learning Curves**
   - mAP50 vs FraÃ§Ã£o de Dados
   - mAP50-95 vs FraÃ§Ã£o de Dados
   - PrecisÃ£o e Recall vs FraÃ§Ã£o
   - Loss (Train/Val) vs FraÃ§Ã£o

2. **RelatÃ³rio Markdown**
   - Tabela comparativa
   - AnÃ¡lise de convergÃªncia
   - RecomendaÃ§Ãµes

## ğŸš€ Como Usar

### Workflow Completo (Todos os Modelos)

```bash
# 1. Criar datasets fracionados
make process-fractions

# 2. Treinar todos os modelos em todas as fraÃ§Ãµes (12 treinamentos)
make train-all-fractions

# 3. Analisar e comparar resultados
make compare-learning-curves

# OU execute tudo de uma vez:
make workflow-learning-curves
```

### Workflow RÃ¡pido (Apenas Nano)

```bash
# Teste rÃ¡pido com apenas o modelo Nano
make workflow-learning-curves-quick
```

### Comandos Individuais

```bash
# Criar fraÃ§Ãµes customizadas
make process-fractions FRACTIONS="0.25 0.50 0.75 1.0"

# Treinar apenas um modelo especÃ­fico
make train-fractions-nano    # YOLOv8n-seg
make train-fractions-small   # YOLOv8s-seg
make train-fractions-medium  # YOLOv8m-seg

# AnÃ¡lise dos resultados
make compare-learning-curves
```

## ğŸ“Š Interpretando os Resultados

### CenÃ¡rio 1: Aprendizado SaudÃ¡vel âœ…

```
FraÃ§Ã£o | mAP50
-------|-------
25%    | 0.65
50%    | 0.75
75%    | 0.82
100%   | 0.87
```

**InterpretaÃ§Ã£o:**
- Crescimento consistente com mais dados
- Modelo estÃ¡ generalizando bem
- Vale a pena coletar mais dados

### CenÃ¡rio 2: SaturaÃ§Ã£o âš ï¸

```
FraÃ§Ã£o | mAP50
-------|-------
25%    | 0.65
50%    | 0.78
75%    | 0.80
100%   | 0.81
```

**InterpretaÃ§Ã£o:**
- Rendimentos decrescentes apÃ³s 50%
- Modelo jÃ¡ aprendeu os padrÃµes principais
- Focar em qualidade, nÃ£o quantidade de dados

### CenÃ¡rio 3: Overfitting ğŸš¨

```
FraÃ§Ã£o | Train Loss | Val Loss
-------|------------|----------
25%    | 0.5        | 0.6
50%    | 0.3        | 0.7
75%    | 0.2        | 0.9
100%   | 0.1        | 1.2
```

**InterpretaÃ§Ã£o:**
- Train loss diminui, val loss aumenta
- Modelo estÃ¡ memorizando
- Precisa de mais regularizaÃ§Ã£o ou dados diversos

## ğŸ“ˆ MÃ©tricas Analisadas

### MÃ©tricas Principais

1. **mAP50** (Mean Average Precision @ IoU 0.50)
   - MÃ©trica principal para detecÃ§Ã£o
   - Quanto maior, melhor

2. **mAP50-95** (Mean Average Precision @ IoU 0.50-0.95)
   - MÃ©trica mais rigorosa
   - Avalia qualidade da detecÃ§Ã£o em mÃºltiplos IoUs

3. **Precision & Recall**
   - Precision: % de prediÃ§Ãµes corretas
   - Recall: % de objetos encontrados

4. **Loss (Train/Val)**
   - ConvergÃªncia do treinamento
   - Detecta overfitting

### MÃ©tricas SecundÃ¡rias

- **Box Loss**: Qualidade das bounding boxes
- **Class Loss**: ClassificaÃ§Ã£o das classes
- **Mask Loss**: Qualidade das mÃ¡scaras de segmentaÃ§Ã£o
- **Training Time**: Tempo por Ã©poca

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### Customizar FraÃ§Ãµes

Edite o Makefile:

```makefile
FRACTIONS := 0.10 0.25 0.50 0.75 1.0
```

### Customizar Ã‰pocas

```makefile
FRACTION_EPOCHS := 150
```

### Usar Dataset Base Diferente

```makefile
BASE_DATA := data/processed/custom_dataset
```

### Customizar HiperparÃ¢metros

Edite os arquivos YAML em `config/yolo/learning_curves/`:

```yaml
epochs: 100
batch: 16
lr0: 0.01
augmentation:
  hsv_h: 0.015
  hsv_s: 0.7
  hsv_v: 0.4
```

## ğŸ§¹ Limpeza

```bash
# Remover apenas datasets fracionados
make clean-fractions

# Remover experimentos de learning curves
make clean-learning-curves

# Limpeza completa
make clean-all
```

## ğŸ“‹ Checklist de ValidaÃ§Ã£o

Antes de treinar:

- [ ] Dataset base processado e validado
- [ ] FraÃ§Ãµes criadas com sucesso
- [ ] Configs YAML verificados
- [ ] GPU disponÃ­vel (recomendado)
- [ ] EspaÃ§o em disco suficiente (~50GB para experimentos completos)

Durante o treinamento:

- [ ] TensorBoard monitorando progresso
- [ ] MÃ©tricas convergindo
- [ ] Sem erros de GPU/memÃ³ria
- [ ] Checkpoints sendo salvos

ApÃ³s anÃ¡lise:

- [ ] GrÃ¡ficos gerados em `outputs/learning_curves/`
- [ ] RelatÃ³rio markdown criado
- [ ] Resultados fazem sentido (curvas crescentes/estÃ¡veis)
- [ ] ConclusÃµes documentadas

## ğŸ“ AplicaÃ§Ã£o no TCC

### SeÃ§Ã£o do TCC Sugerida

**"4.5 AnÃ¡lise de Curvas de Aprendizado"**

1. **Metodologia**
   - Explicar o processo de fracionamento
   - Justificar as fraÃ§Ãµes escolhidas (25%, 50%, 75%, 100%)
   - Descrever hiperparÃ¢metros consistentes

2. **Experimentos**
   - Apresentar tabelas de resultados
   - Incluir grÃ¡ficos de learning curves
   - Comparar os 3 modelos (Nano, Small, Medium)

3. **AnÃ¡lise**
   - Discutir comportamento de cada modelo
   - Identificar ponto de saturaÃ§Ã£o (se houver)
   - Validar ausÃªncia de overfitting

4. **ConclusÃµes**
   - Modelos estÃ£o aprendendo genuinamente?
   - Qual fraÃ§Ã£o de dados Ã© suficiente?
   - RecomendaÃ§Ãµes para coleta de dados futura

## ğŸ“š ReferÃªncias

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [Learning Curves in ML](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)
- [Deep Learning Book - Regularization](https://www.deeplearningbook.org/contents/regularization.html)

## ğŸ¤ Contribuindo

Para adicionar novos tipos de anÃ¡lise:

1. Edite `scripts/compare_learning_curves.py`
2. Adicione novas funÃ§Ãµes de plotting
3. Atualize o relatÃ³rio markdown
4. Teste com experimentos existentes

## ğŸ“ Suporte

Em caso de problemas:

1. Verifique logs em `experiments/learning_curve_*/`
2. Consulte `docs/SOLUCAO_PROBLEMAS.md`
3. Execute `make diagnose` nos dados processados
4. Valide GPUs com `make test-cuda`

---

**âœ¨ Bom treinamento e anÃ¡lise! âœ¨**

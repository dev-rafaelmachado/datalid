# ‚ùì FAQ - Enhanced PARSeq OCR

## Perguntas Frequentes

### üìã Geral

#### Q: Qual √© o ganho de acur√°cia esperado?
**A:** Com o pipeline completo, esperamos:
- **CER:** 15.23% ‚Üí 3.12% (redu√ß√£o de 81%)
- **Exact Match:** 45% ‚Üí 91% (ganho de +46 pontos percentuais)

#### Q: Quanto tempo leva para processar uma imagem?
**A:** Depende da configura√ß√£o:
- **Baseline:** ~0.8s
- **Full pipeline:** ~3.5s
- **Com CUDA:** ~1.5s (full pipeline)

#### Q: Funciona em imagens de baixa qualidade?
**A:** Sim! O pipeline foi otimizado para imagens dif√≠ceis com:
- Sombras fortes
- Ilumina√ß√£o irregular
- Rota√ß√µes (at√© 15¬∞)
- M√∫ltiplas linhas
- Fontes variadas

---

### ‚öôÔ∏è Configura√ß√£o

#### Q: Quais par√¢metros devo ajustar primeiro?
**A:** Para imagens dif√≠ceis, ajuste nesta ordem:
1. `clahe_clip_limit`: aumentar para 1.6-1.8
2. `shadow_removal`: habilitar
3. `enable_ensemble`: habilitar com `ensemble_strategy='rerank'`
4. `max_rotation_angle`: aumentar para 10¬∞ se houver rota√ß√µes

#### Q: Quando desabilitar o ensemble?
**A:** Desabilite se:
- Imagens de alta qualidade (CER baseline < 5%)
- Processamento em tempo real (<1s necess√°rio)
- GPU limitada

#### Q: `enable_perspective` deve estar habilitado?
**A:** **Geralmente N√ÉO**. Perspective warp pode distorcer imagens. Use apenas se:
- Imagens com perspectiva forte (fotografias anguladas)
- Testou e validou que melhora acur√°cia
- Sanity checks est√£o funcionando

#### Q: Qual `clahe_clip_limit` usar?
**A:**
- **Alta qualidade:** 1.2-1.4 (suave)
- **Qualidade m√©dia:** 1.5-1.6 (recomendado)
- **Baixa qualidade/sombras:** 1.7-1.8 (agressivo)
- **Muito ru√≠do:** 1.2-1.4 (evitar amplificar ru√≠do)

**Nunca usar > 2.5** (amplifica ru√≠do excessivamente)

---

### üîç Line Detection

#### Q: Linhas n√£o est√£o sendo detectadas corretamente
**A:** Tente:
1. Reduzir `min_line_height` de 10 para 8
2. Ajustar `dbscan_eps`:
   - Se linhas muito pr√≥ximas: reduzir para 10
   - Se linhas separadas: aumentar para 20
3. Mudar `clustering_method` para `agglomerative`
4. Usar `method='hybrid'` (geralmente melhor)

#### Q: Detec√ß√£o de rota√ß√£o n√£o funciona
**A:** Verifique:
- `enable_rotation_detection: true`
- Rota√ß√£o est√° dentro do limite (`max_rotation_angle`)
- Imagem tem bordas/linhas suficientes para Hough Transform
- Se rota√ß√£o > 15¬∞, considere pr√©-processamento manual

#### Q: Ordem das linhas est√° errada
**A:** Linhas s√£o ordenadas top-to-bottom automaticamente. Se errado:
- Verificar se detec√ß√£o est√° agrupando linhas corretamente
- Aumentar `dbscan_eps` para separar melhor
- Visualizar com `engine.line_detector.visualize_lines()`

---

### üé® Normaliza√ß√£o

#### Q: Shadow removal est√° piorando a imagem
**A:** Isso pode acontecer se:
- Imagem j√° tem boa ilumina√ß√£o ‚Üí desabilitar
- `shadow_ksize` muito grande ‚Üí reduzir para 15
- Sombras s√£o parte do conte√∫do ‚Üí desabilitar

#### Q: CLAHE est√° amplificando ru√≠do
**A:**
- Reduzir `clahe_clip_limit` para 1.2-1.4
- Aumentar denoise antes: `denoise_method='bilateral'`
- Considerar usar apenas variante `baseline`

#### Q: Sharpen est√° criando artefatos
**A:**
- Reduzir `sharpen_strength` para 0.2-0.3
- Ou desabilitar: `sharpen_enabled: false`
- Sharpen funciona melhor em imagens j√° boas

---

### üéØ Ensemble & Reranking

#### Q: Qual estrat√©gia de ensemble √© melhor?
**A:**
- **`rerank`**: Melhor para acur√°cia (recomendado)
- **`voting`**: Melhor se m√∫ltiplas variantes concordam
- **`confidence`**: Mais r√°pido, mas menos preciso

#### Q: Quantas variantes s√£o geradas?
**A:** 7 variantes por padr√£o:
1. baseline
2. clahe
3. clahe_strong
4. threshold
5. invert
6. adaptive_threshold
7. sharp (se habilitado)

#### Q: Como saber qual variante foi escolhida?
**A:** Habilite logging detalhado:
```python
from loguru import logger
logger.add("debug.log", level="DEBUG")
```

Voc√™ ver√°:
```
üèÜ Melhor variante: 'clahe' (score: 1.115)
```

---

### üìù P√≥s-processamento

#### Q: Fuzzy matching n√£o est√° funcionando
**A:** Verifique:
1. `python-Levenshtein` instalado:
   ```bash
   pip install python-Levenshtein
   ```
2. `enable_fuzzy_match: true`
3. Palavras em `known_words` est√£o corretas
4. `fuzzy_threshold` n√£o muito baixo (recomendado: 2)

#### Q: Mapeamento contextual est√° trocando caracteres errados
**A:** Mapeamento usa contexto (num√©rico vs alfab√©tico). Se errado:
- Revisar texto esperado
- Desabilitar: `ambiguity_mapping: false`
- Ajustar regex em `expected_formats`

#### Q: Formato conhecido n√£o est√° sendo corrigido
**A:**
- Verificar se padr√£o est√° em `expected_formats`
- Adicionar regex customizado:
  ```yaml
  expected_formats:
    - 'SEU_PADRAO_\d+'
  ```
- Habilitar: `fix_formats: true`

---

### üß™ Experimenta√ß√£o

#### Q: Como executar ablation test?
**A:**
```python
from src.ocr.experiment_utils import ExperimentRunner, ConfigurationPresets

runner = ExperimentRunner()
configs = ConfigurationPresets.get_ablation_configs()

results = runner.run_ablation_test(engine, images, truths, configs)
```

Ou via CLI:
```bash
python scripts/ocr/demo_enhanced_parseq.py --mode ablation --image test.jpg --ground-truth "LOT123"
```

#### Q: O que √© CER e qual valor √© bom?
**A:** CER = Character Error Rate (taxa de erro de caracteres)

- **Excelente:** < 0.03 (3%)
- **Bom:** < 0.05 (5%)
- **Aceit√°vel:** < 0.10 (10%)
- **Ruim:** > 0.15 (15%)

#### Q: Como calcular CER manualmente?
**A:**
```python
from src.ocr.experiment_utils import ExperimentRunner

runner = ExperimentRunner()
cer = runner._calculate_cer("predi√ß√£o", "verdade")
print(f"CER: {cer:.4f}")
```

---

### üöÄ Performance

#### Q: Como acelerar o processamento?
**A:**
1. **Usar CUDA:**
   ```python
   config['device'] = 'cuda'
   ```
2. **Desabilitar ensemble** (imagens simples):
   ```python
   config['enable_ensemble'] = False
   ```
3. **Reduzir variantes:**
   ```python
   # Manter apenas baseline e clahe
   ```
4. **Modelo menor:**
   ```python
   config['model_name'] = 'parseq_tiny'  # vs 'parseq' ou 'parseq_patch16_224'
   ```

#### Q: GPU out of memory
**A:**
- Reduzir `batch_size` de 8 para 1
- Usar `parseq_tiny` ao inv√©s de modelos maiores
- Processar imagens em lotes menores
- Resize imagens antes: max 1000px largura

#### Q: CPU est√° muito lento
**A:**
- Usar GPU se dispon√≠vel
- Desabilitar ensemble
- Processar em paralelo (multiprocessing)
- Considerar modelo mais leve (`parseq_tiny`)

---

### üêõ Erros Comuns

#### Q: `ImportError: No module named 'Levenshtein'`
**A:**
```bash
pip install python-Levenshtein

# Ou no Windows:
pip install python-Levenshtein-wheels
```

**Nota:** C√≥digo funciona sem Levenshtein (usa fallback), mas fuzzy matching ser√° desabilitado.

#### Q: `CUDA out of memory`
**A:**
```python
# Usar CPU
config['device'] = 'cpu'

# Ou reduzir batch size
config['batch_size'] = 1
```

#### Q: `AttributeError: 'NoneType' object has no attribute 'shape'`
**A:** Imagem n√£o carregou corretamente:
```python
image = cv2.imread('path.jpg')
if image is None:
    print("Erro ao carregar imagem!")
```

#### Q: Linhas detectadas mas texto vazio
**A:**
- Verificar se modelo foi inicializado: `engine.initialize()`
- Verificar device (cuda vs cpu)
- Verificar se imagem tem texto vis√≠vel
- Testar com imagem simples primeiro

---

### üéì Fine-tuning

#### Q: Quando fazer fine-tuning?
**A:** Considere se:
- CER > 5% ap√≥s pipeline completo
- Exact Match < 70%
- Dom√≠nio muito espec√≠fico (fontes √∫nicas, layouts customizados)
- Tem 500+ exemplos anotados

#### Q: Quantos exemplos preciso?
**A:**
- **M√≠nimo:** 500 exemplos
- **Recomendado:** 1000-2000 exemplos
- **Ideal:** 5000+ exemplos

**Por linha**, n√£o por imagem!

#### Q: Como anotar dados para fine-tuning?
**A:**
1. Formato: imagem + texto em arquivo `.txt`
2. Um arquivo por linha de texto
3. Texto exato (incluindo espa√ßos, pontua√ß√£o)
4. Diversidade: diferentes fontes, √¢ngulos, ilumina√ß√µes

#### Q: Qual learning rate usar?
**A:**
- **In√≠cio:** 1e-4 (0.0001)
- **Ajuste fino:** 5e-5 (0.00005)
- **Se divergir:** 1e-5 (0.00001)

Use learning rate scheduler (cosine annealing recomendado).

---

### üí° Dicas e Truques

#### Q: Como visualizar linhas detectadas?
**A:**
```python
line_bboxes = engine.line_detector.detect_lines(image)
vis = engine.line_detector.visualize_lines(image, line_bboxes)
cv2.imwrite('lines_debug.jpg', vis)
```

#### Q: Como salvar variantes fotom√©tricas?
**A:**
```python
variants = engine.photometric_normalizer.generate_variants(image)
for name, img in variants.items():
    cv2.imwrite(f'variant_{name}.jpg', img)
```

#### Q: Como adicionar palavra nova ao fuzzy matching?
**A:**
```python
config['postprocessor']['known_words'].append('NOVA_PALAVRA')
```

#### Q: Como desabilitar logging excessivo?
**A:**
```python
from loguru import logger
logger.remove()
logger.add(sys.stderr, level="INFO")  # ou "WARNING"
```

---

### üìä Compara√ß√£o

#### Q: PARSeq vs Tesseract vs EasyOCR?
**A:**

| Aspecto | PARSeq | Tesseract | EasyOCR |
|---------|--------|-----------|---------|
| Acur√°cia (geral) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Velocidade | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| Fontes variadas | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Multi-l√≠ngua | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Fine-tuning | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

**PARSeq** √© melhor para fontes variadas e fine-tuning.

#### Q: parseq_tiny vs parseq vs parseq_patch16_224?
**A:**

| Modelo | Tamanho | Velocidade | Acur√°cia | Uso Recomendado |
|--------|---------|------------|----------|-----------------|
| parseq_tiny | Pequeno | R√°pido | Boa | Produ√ß√£o, batch |
| parseq | M√©dio | M√©dio | Muito Boa | Balanceado |
| parseq_patch16_224 | Grande | Lento | Excelente | M√°xima acur√°cia |

**Recomenda√ß√£o:** Comece com `parseq_tiny`, use `parseq_patch16_224` se CER > 5%.

---

### üîß Troubleshooting Avan√ßado

#### Q: Pipeline completo mas CER ainda > 10%
**A:** Causas poss√≠veis:
1. **Imagens muito degradadas:**
   - Aumentar `clahe_clip_limit` para 1.8-2.0
   - Habilitar `sharpen_enabled`
   - Considerar pr√©-processamento adicional

2. **Fontes muito diferentes:**
   - Fine-tuning necess√°rio
   - Testar modelo maior (`parseq_patch16_224`)

3. **Multi-script (alfabetos diferentes):**
   - PARSeq √© treinado principalmente em alfabeto latino
   - Considerar modelos espec√≠ficos por idioma

4. **Layout complexo:**
   - Melhorar line detection
   - Pr√©-processamento manual de crops

#### Q: Confian√ßa alta mas texto errado
**A:**
- Modelo est√° "confiante mas errado"
- Indica necessidade de fine-tuning
- Ou ajustar reranking para dar mais peso a formato

#### Q: Texto correto em uma variante mas reranking escolhe errada
**A:**
- Habilitar logging detalhado para ver scores
- Ajustar pesos em `_rerank_results`
- Considerar `ensemble_strategy='voting'` ao inv√©s de `rerank`

---

### üìö Recursos Adicionais

#### Q: Onde encontrar documenta√ß√£o completa?
**A:**
- **Guia completo:** `docs/ENHANCED_PARSEQ_GUIDE.md`
- **Exemplos:** `docs/CODE_EXAMPLES.md`
- **Checklist:** `docs/IMPLEMENTATION_CHECKLIST.md`
- **Config:** `config/ocr/enhanced_parseq_full.yaml`

#### Q: Como contribuir/reportar bugs?
**A:**
- Documentar erro detalhadamente
- Incluir imagem de exemplo (se poss√≠vel)
- Incluir configura√ß√£o usada
- Incluir log de erro completo

#### Q: Onde aprender mais sobre PARSeq?
**A:**
- Paper: "Scene Text Recognition with Permuted Autoregressive Sequence Models"
- Repo oficial: https://github.com/baudm/parseq
- Tutorial: https://github.com/baudm/parseq/blob/main/Notebooks/

---

## üí¨ Perguntas N√£o Respondidas?

Se sua pergunta n√£o est√° aqui:
1. Consulte a documenta√ß√£o completa: `docs/ENHANCED_PARSEQ_GUIDE.md`
2. Veja exemplos de c√≥digo: `docs/CODE_EXAMPLES.md`
3. Revise a configura√ß√£o: `config/ocr/enhanced_parseq_full.yaml`

---

**√öltima atualiza√ß√£o:** 19 de Outubro de 2025

# ğŸ“Š Exemplos de Outputs - AnÃ¡lise e ComparaÃ§Ã£o

Este documento mostra exemplos reais de saÃ­das dos scripts de anÃ¡lise.

---

## ğŸ” Error Analysis - SaÃ­da no Terminal

```
ğŸ” ANÃLISE DE ERROS YOLO - DATALID 3.0
============================================================
ğŸ” Error Analyzer inicializado
  â€¢ Modelo: experiments/nano-seg-10e/weights/best.pt
  â€¢ Dataset: data/processed/v1_segment
  â€¢ Classes: 4

ğŸ” Analisando erros no split 'val'...
ğŸ“Š Analisando 250 imagens...
  Progresso: 50/250
  Progresso: 100/250
  Progresso: 150/250
  Progresso: 200/250
  Progresso: 250/250

ğŸ’¾ Resultados salvos: outputs/error_analysis/nano-seg-10e/error_analysis.json
ğŸ’¾ MÃ©tricas por classe salvas: outputs/error_analysis/nano-seg-10e/class_metrics.csv
ğŸ¨ Gerando visualizaÃ§Ãµes...
ğŸ“Š GrÃ¡fico de tipos de erros salvo
ğŸ“Š GrÃ¡fico de mÃ©tricas por classe salvo
ğŸ“Š GrÃ¡fico de distribuiÃ§Ã£o IoU salvo
ğŸ“Š Matriz de misclassification salva
âœ… AnÃ¡lise concluÃ­da! Resultados em: outputs/error_analysis/nano-seg-10e

============================================================
ğŸ” RESUMO DA ANÃLISE DE ERROS
============================================================

ğŸ“Š MÃ‰TRICAS GLOBAIS:
  â€¢ Precision: 0.867
  â€¢ Recall: 0.821
  â€¢ F1 Score: 0.843
  â€¢ Average IoU: 0.735

ğŸ“ˆ CONTAGENS:
  â€¢ True Positives: 1453
  â€¢ False Positives: 223
  â€¢ False Negatives: 317
  â€¢ Misclassifications: 45

ğŸ¯ MÃ‰TRICAS POR CLASSE:
  tampa:
    â€¢ Precision: 0.912
    â€¢ Recall: 0.885
    â€¢ F1: 0.898
    â€¢ Avg IoU: 0.782
    â€¢ TP/FP/FN: 456/44/59
  
  corpo:
    â€¢ Precision: 0.845
    â€¢ Recall: 0.798
    â€¢ F1: 0.821
    â€¢ Avg IoU: 0.712
    â€¢ TP/FP/FN: 398/73/101
  
  rotulo:
    â€¢ Precision: 0.823
    â€¢ Recall: 0.756
    â€¢ F1: 0.788
    â€¢ Avg IoU: 0.698
    â€¢ TP/FP/FN: 342/73/110
  
  codigo:
    â€¢ Precision: 0.887
    â€¢ Recall: 0.845
    â€¢ F1: 0.865
    â€¢ Avg IoU: 0.748
    â€¢ TP/FP/FN: 257/33/47

============================================================

âœ… AnÃ¡lise de erros concluÃ­da!
```

---

## ğŸ“Š Model Comparison - SaÃ­da no Terminal

```
ğŸ“Š COMPARAÃ‡ÃƒO DE MODELOS YOLO - DATALID 3.0
============================================================
ğŸ“Š Comparador de Modelos inicializado
  â€¢ DiretÃ³rio: experiments

ğŸ” Descobrindo modelos...
ğŸ“Š Descobertos 6 modelos
ğŸ“Š Comparando 6 modelos...
âœ… ComparaÃ§Ã£o concluÃ­da com 18 colunas

ğŸ† RANKING POR MAP50:
  1. final-medium-segment - 0.923
  2. final-small-segment - 0.895
  3. final-nano-segment - 0.867
  4. nano-seg-10e-aug - 0.845
  5. nano-seg-10e - 0.823
  6. nano-10e - 0.789

ğŸ“ Gerando relatÃ³rio de comparaÃ§Ã£o...
ğŸ’¾ ComparaÃ§Ã£o salva: outputs/model_comparison/model_comparison.csv
ğŸ’¾ ComparaÃ§Ã£o JSON salva: outputs/model_comparison/model_comparison.json
ğŸ¨ Gerando visualizaÃ§Ãµes...
âœ… VisualizaÃ§Ãµes geradas
ğŸ“ RelatÃ³rio Markdown salvo: outputs/model_comparison/comparison_report.md

============================================================
ğŸ“Š RESUMO DA COMPARAÃ‡ÃƒO DE MODELOS
============================================================

ğŸ“ˆ MODELOS ANALISADOS: 6

  ğŸ¤– final-medium-segment:
    â€¢ mAP@0.5: 0.923
    â€¢ mAP@0.5:0.95: 0.687
    â€¢ Precision: 0.915
    â€¢ Recall: 0.892
    â€¢ Epochs: 150

  ğŸ¤– final-small-segment:
    â€¢ mAP@0.5: 0.895
    â€¢ mAP@0.5:0.95: 0.658
    â€¢ Precision: 0.889
    â€¢ Recall: 0.876
    â€¢ Epochs: 150

  ğŸ¤– final-nano-segment:
    â€¢ mAP@0.5: 0.867
    â€¢ mAP@0.5:0.95: 0.623
    â€¢ Precision: 0.867
    â€¢ Recall: 0.845
    â€¢ Epochs: 150

  ğŸ¤– nano-seg-10e-aug:
    â€¢ mAP@0.5: 0.845
    â€¢ mAP@0.5:0.95: 0.598
    â€¢ Precision: 0.843
    â€¢ Recall: 0.823
    â€¢ Epochs: 10

  ğŸ¤– nano-seg-10e:
    â€¢ mAP@0.5: 0.823
    â€¢ mAP@0.5:0.95: 0.576
    â€¢ Precision: 0.825
    â€¢ Recall: 0.801
    â€¢ Epochs: 10

  ğŸ¤– nano-10e:
    â€¢ mAP@0.5: 0.789
    â€¢ mAP@0.5:0.95: 0.542
    â€¢ Precision: 0.798
    â€¢ Recall: 0.778
    â€¢ Epochs: 10

ğŸ† MELHOR MODELO:
  â€¢ Nome: final-medium-segment
  â€¢ mAP@0.5: 0.923

============================================================

âœ… ComparaÃ§Ã£o concluÃ­da! RelatÃ³rio: outputs/model_comparison/comparison_report.md
```

---

## ğŸ“„ error_analysis.json (Exemplo)

```json
{
  "global_metrics": {
    "total_true_positives": 1453,
    "total_false_positives": 223,
    "total_false_negatives": 317,
    "total_misclassifications": 45,
    "precision": 0.867,
    "recall": 0.821,
    "f1_score": 0.843,
    "avg_iou": 0.735
  },
  "class_metrics": {
    "tampa": {
      "tp": 456,
      "fp": 44,
      "fn": 59,
      "total_gt": 515,
      "total_pred": 500,
      "precision": 0.912,
      "recall": 0.885,
      "f1": 0.898,
      "avg_iou": 0.782
    },
    "corpo": {
      "tp": 398,
      "fp": 73,
      "fn": 101,
      "total_gt": 499,
      "total_pred": 471,
      "precision": 0.845,
      "recall": 0.798,
      "f1": 0.821,
      "avg_iou": 0.712
    }
  },
  "error_breakdown": {
    "false_positives": [
      {
        "image": "data/processed/v1_segment/val/images/img_001.jpg",
        "confidence": 0.78,
        "class": 0,
        "best_iou": 0.23
      }
    ],
    "false_negatives": [
      {
        "image": "data/processed/v1_segment/val/images/img_002.jpg",
        "class": 2
      }
    ],
    "misclassifications": [
      {
        "image": "data/processed/v1_segment/val/images/img_003.jpg",
        "pred_class": 1,
        "gt_class": 2,
        "iou": 0.67,
        "confidence": 0.82
      }
    ]
  }
}
```

---

## ğŸ“„ class_metrics.csv (Exemplo)

```csv
class,tp,fp,fn,total_gt,total_pred,precision,recall,f1,avg_iou
tampa,456,44,59,515,500,0.912,0.885,0.898,0.782
corpo,398,73,101,499,471,0.845,0.798,0.821,0.712
rotulo,342,73,110,452,415,0.823,0.756,0.788,0.698
codigo,257,33,47,304,290,0.887,0.845,0.865,0.748
```

---

## ğŸ“„ model_comparison.csv (Exemplo)

```csv
model,map50,map50_95,precision,recall,box_loss,val_box_loss,total_epochs,training_time,model_size,config_epochs,config_batch,config_imgsz,config_model
final-medium-segment,0.923,0.687,0.915,0.892,0.023,0.031,150,8.5,48.3,150,16,640,yolov8m-seg.pt
final-small-segment,0.895,0.658,0.889,0.876,0.028,0.035,150,5.2,22.1,150,16,640,yolov8s-seg.pt
final-nano-segment,0.867,0.623,0.867,0.845,0.032,0.042,150,3.1,6.2,150,16,640,yolov8n-seg.pt
nano-seg-10e-aug,0.845,0.598,0.843,0.823,0.035,0.045,10,0.3,6.2,10,16,640,yolov8n-seg.pt
nano-seg-10e,0.823,0.576,0.825,0.801,0.038,0.048,10,0.3,6.2,10,16,640,yolov8n-seg.pt
nano-10e,0.789,0.542,0.798,0.778,0.045,0.055,10,0.2,6.0,10,16,640,yolov8n.pt
```

---

## ğŸ“„ comparison_report.md (Trecho)

```markdown
# ğŸ“Š Model Comparison Report

**Generated:** 2025-10-14 15:30:45
**Experiments Directory:** experiments
**Total Models:** 6

---

## ğŸ“‹ Models Summary

### final-medium-segment
- **Status:** completed
- **Configuration:**
  - Epochs: 150
  - Batch Size: 16
  - Image Size: 640
  - Model: yolov8m-seg.pt
- **Training Time:** 8.50 hours
- **Model Size:** 48.30 MB

### final-small-segment
- **Status:** completed
- **Configuration:**
  - Epochs: 150
  - Batch Size: 16
  - Image Size: 640
  - Model: yolov8s-seg.pt
- **Training Time:** 5.20 hours
- **Model Size:** 22.10 MB

## ğŸ“Š Metrics Comparison

| model | map50 | map50_95 | precision | recall | total_epochs |
|-------|-------|----------|-----------|--------|--------------|
| final-medium-segment | 0.923 | 0.687 | 0.915 | 0.892 | 150 |
| final-small-segment | 0.895 | 0.658 | 0.889 | 0.876 | 150 |
| final-nano-segment | 0.867 | 0.623 | 0.867 | 0.845 | 150 |

## ğŸ† Rankings

### By mAP@0.5

1. **final-medium-segment** - 0.923
2. **final-small-segment** - 0.895
3. **final-nano-segment** - 0.867
4. **nano-seg-10e-aug** - 0.845
5. **nano-seg-10e** - 0.823

## ğŸ’¡ Recommendations

- **Best Performance:** final-medium-segment (mAP@0.5: 0.923)
- **Smallest Model:** nano-seg-10e (6.20 MB)
- **Fastest Training:** nano-10e (0.20 hours)
```

---

## ğŸ¨ VisualizaÃ§Ãµes Geradas

### 1. error_types.png
GrÃ¡fico de barras mostrando:
- ğŸŸ¢ True Positives: 1453
- ğŸŸ  False Positives: 223
- ğŸ”´ False Negatives: 317
- ğŸŸ£ Misclassifications: 45

### 2. class_metrics.png
4 subplots mostrando por classe:
- Precision (barras horizontais)
- Recall (barras horizontais)
- F1 Score (barras horizontais)
- Average IoU (barras horizontais)

### 3. iou_distribution.png
Histograma de IoU scores dos True Positives com:
- Linha vertical vermelha: IoU mÃ©dio (0.735)
- Linha vertical verde: Threshold (0.5)

### 4. misclassification_matrix.png
Heatmap mostrando confusÃµes entre classes:
```
        tampa  corpo  rotulo  codigo
tampa     0      8      3       2
corpo     12     0      15      5
rotulo    5      18     0       8
codigo    3      7      6       0
```

### 5. map50_comparison.png
Barras comparando mAP@0.5 de todos os modelos

### 6. precision_recall.png
Scatter plot com cada modelo como ponto no espaÃ§o P-R

### 7. metrics_radar.png
Radar chart mostrando mÃºltiplas mÃ©tricas normalizadas

### 8. efficiency.png
Scatter plot: Training Time (x) vs mAP@0.5 (y)

### 9. size_vs_performance.png
Scatter plot: Model Size (x) vs mAP@0.5 (y)

### 10. metrics_heatmap.png
Heatmap normalizado com todas as mÃ©tricas de todos os modelos

---

## ğŸ“ Estrutura Completa de Outputs

```
outputs/
â”œâ”€â”€ error_analysis/
â”‚   â””â”€â”€ nano-seg-10e/
â”‚       â”œâ”€â”€ error_analysis.json
â”‚       â”œâ”€â”€ class_metrics.csv
â”‚       â”œâ”€â”€ visualizations/
â”‚       â”‚   â”œâ”€â”€ error_types.png
â”‚       â”‚   â”œâ”€â”€ class_metrics.png
â”‚       â”‚   â”œâ”€â”€ iou_distribution.png
â”‚       â”‚   â””â”€â”€ misclassification_matrix.png
â”‚       â””â”€â”€ errors/
â”‚           â”œâ”€â”€ img_001_errors.jpg
â”‚           â”œâ”€â”€ img_002_errors.jpg
â”‚           â””â”€â”€ ... (imagens com erros anotados)
â”‚
â””â”€â”€ model_comparison/
    â”œâ”€â”€ comparison_report.md
    â”œâ”€â”€ model_comparison.csv
    â”œâ”€â”€ model_comparison.json
    â””â”€â”€ visualizations/
        â”œâ”€â”€ map50_comparison.png
        â”œâ”€â”€ map50_95_comparison.png
        â”œâ”€â”€ precision_recall.png
        â”œâ”€â”€ metrics_radar.png
        â”œâ”€â”€ efficiency.png
        â”œâ”€â”€ size_vs_performance.png
        â””â”€â”€ metrics_heatmap.png
```

---

## ğŸ’¡ Como Interpretar

### Error Analysis

1. **error_analysis.json**: Dados brutos para anÃ¡lise programÃ¡tica
2. **class_metrics.csv**: Abra no Excel para comparar classes
3. **visualizations/**: Revise todos os grÃ¡ficos para insights
4. **errors/**: Examine visualmente os erros do modelo

### Model Comparison

1. **comparison_report.md**: Leia primeiro para overview
2. **model_comparison.csv**: Use para filtrar/ordenar no Excel
3. **visualizations/map50_comparison.png**: Identificar melhor modelo
4. **visualizations/efficiency.png**: Escolher baseado em custo-benefÃ­cio
5. **visualizations/size_vs_performance.png**: Escolher para deployment

---

## ğŸ¯ DecisÃµes Baseadas nos Outputs

### Se precisar de Alta Precision
â†’ Escolha modelo com menos FP em `error_types.png`

### Se precisar de Alta Recall
â†’ Escolha modelo com menos FN em `error_types.png`

### Para ProduÃ§Ã£o em Edge Device
â†’ Use `size_vs_performance.png` para escolher modelo pequeno e eficiente

### Para Otimizar Custo de Treinamento
â†’ Use `efficiency.png` para escolher melhor tempo/performance

### Para Melhorar Classe EspecÃ­fica
â†’ Revise `class_metrics.csv` e imagens em `errors/` da classe problemÃ¡tica

---

**Dica**: Os outputs sÃ£o autoexplicativos - comece pelos grÃ¡ficos PNG e depois explore os CSVs/JSONs para detalhes! ğŸ“Šâœ¨

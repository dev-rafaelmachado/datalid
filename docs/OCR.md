# ğŸ”¤ MÃ³dulo OCR - Datalid 3.0

Sistema completo de OCR (Optical Character Recognition) para extraÃ§Ã£o de datas de validade.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Engines Suportados](#engines-suportados)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Workflow Completo](#workflow-completo)
- [Comandos Makefile](#comandos-makefile)
- [Estrutura de Arquivos](#estrutura-de-arquivos)
- [Exemplos de Uso](#exemplos-de-uso)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)

---

## ğŸ¯ VisÃ£o Geral

O mÃ³dulo OCR do Datalid fornece:

- **4 engines OCR**: Tesseract, EasyOCR, PaddleOCR, TrOCR
- **3 nÃ­veis de prÃ©-processamento**: minimal, medium, heavy
- **Benchmark automÃ¡tico**: ComparaÃ§Ã£o de performance e acurÃ¡cia
- **Pipeline completo**: YOLO â†’ OCR â†’ Parse de datas
- **VisualizaÃ§Ãµes**: GrÃ¡ficos comparativos e anÃ¡lises

---

## ğŸ”§ Engines Suportados

| Engine | Velocidade | AcurÃ¡cia | Uso de GPU | ObservaÃ§Ãµes |
|--------|-----------|----------|-----------|-------------|
| **Tesseract** | âš¡âš¡âš¡ | â­â­ | âŒ | RÃ¡pido, mas menos preciso em textos complexos |
| **EasyOCR** | âš¡âš¡ | â­â­â­ | âœ… | Bom equilÃ­brio entre velocidade e acurÃ¡cia |
| **PaddleOCR** | âš¡âš¡âš¡ | â­â­â­â­ | âœ… | Recomendado - melhor acurÃ¡cia geral |
| **TrOCR** | âš¡ | â­â­â­â­ | âœ… | Transformer-based, mais lento mas preciso |

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar todos os engines

```bash
make ocr-setup
```

Este comando instala:
- PyTesseract, EasyOCR, PaddleOCR, Transformers
- Backends necessÃ¡rios (PyTorch, PaddlePaddle)

### 2. Instalar Tesseract (opcional, mas recomendado)

**Windows:**
```bash
# Via Chocolatey
choco install tesseract

# Ou baixe: https://github.com/UB-Mannheim/tesseract/wiki
```

**Linux:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-por
```

**macOS:**
```bash
brew install tesseract tesseract-lang
```

---

## ğŸš€ Workflow Completo

### Passo 1: Preparar Dataset OCR

Primeiro, execute uma prediÃ§Ã£o YOLO para obter crops das datas:

```bash
# Executar prediÃ§Ã£o YOLO
make predict-dir MODEL=experiments/yolov8s_seg_final/weights/best.pt DIR=data/test_images

# Preparar dataset OCR a partir das detecÃ§Ãµes
make ocr-prepare-data DETECTIONS=outputs/predictions
```

**SaÃ­da:**
- `data/ocr_test/images/` - Crops das datas detectadas
- `data/ocr_test/metadata.json` - Metadados das detecÃ§Ãµes
- `data/ocr_test/ground_truth.json` - Template para anotaÃ§Ã£o

### Passo 2: Anotar Ground Truth

Use a interface grÃ¡fica para anotar o texto correto:

```bash
make ocr-annotate
```

Ou anote manualmente o arquivo `data/ocr_test/ground_truth.json`:

```json
{
  "annotations": {
    "crop_0000.jpg": "31/12/2025",
    "crop_0001.jpg": "15/06/2024",
    "crop_0002.jpg": "20/03/2026"
  }
}
```

### Passo 3: Comparar Engines OCR

```bash
make ocr-compare
```

**Resultados:**
- `outputs/ocr_benchmarks/comparison/comparison_summary.csv` - Resumo
- `outputs/ocr_benchmarks/comparison/comparison_summary.png` - GrÃ¡ficos
- `outputs/ocr_benchmarks/comparison/all_results.csv` - Resultados detalhados

### Passo 4: Testar PrÃ©-processamento

```bash
make prep-compare
```

**Resultados:**
- `outputs/preprocessing_tests/results.csv` - ComparaÃ§Ã£o
- `outputs/preprocessing_tests/comparison.png` - VisualizaÃ§Ã£o
- `outputs/preprocessing_tests/{minimal,medium,heavy}/` - Imagens processadas

### Passo 5: Workflow Completo (AutomÃ¡tico)

Execute tudo de uma vez:

```bash
make workflow-ocr
```

---

## ğŸ“ Comandos Makefile

### Setup e InstalaÃ§Ã£o

```bash
make ocr-setup              # Instala engines OCR
```

### PreparaÃ§Ã£o de Dados

```bash
make ocr-prepare-data       # Prepara dataset OCR
make ocr-annotate          # Interface de anotaÃ§Ã£o
```

### Testes de Engines

```bash
make ocr-test ENGINE=paddleocr     # Testa engine especÃ­fico
make ocr-compare                    # Compara todos os engines
make ocr-benchmark                  # Benchmark completo
```

### Testes de PrÃ©-processamento

```bash
make prep-test LEVEL=medium        # Testa nÃ­vel especÃ­fico
make prep-compare                   # Compara todos os nÃ­veis
```

### Pipeline Completo

```bash
make pipeline-test                  # Testa pipeline YOLO + OCR
make pipeline-run IMAGE=test.jpg    # Executa em imagem
```

### Experimentos e VisualizaÃ§Ã£o

```bash
make exp-ocr-comparison            # Experimento completo
make viz-ocr-results              # Gera grÃ¡ficos OCR
make viz-preprocessing            # Gera grÃ¡ficos preprocessing
```

### Workflow e Limpeza

```bash
make workflow-ocr                  # Workflow completo
make clean-ocr                     # Limpa dados OCR
```

---

## ğŸ“ Estrutura de Arquivos

```
datalid3.0/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ ocr/                      # Configs dos engines
â”‚   â”‚   â”œâ”€â”€ default.yaml
â”‚   â”‚   â”œâ”€â”€ tesseract.yaml
â”‚   â”‚   â”œâ”€â”€ easyocr.yaml
â”‚   â”‚   â”œâ”€â”€ paddleocr.yaml
â”‚   â”‚   â””â”€â”€ trocr.yaml
â”‚   â”œâ”€â”€ preprocessing/            # Configs de prÃ©-processamento
â”‚   â”‚   â”œâ”€â”€ minimal.yaml
â”‚   â”‚   â”œâ”€â”€ medium.yaml
â”‚   â”‚   â””â”€â”€ heavy.yaml
â”‚   â”œâ”€â”€ pipeline/                 # Configs do pipeline
â”‚   â”‚   â””â”€â”€ full_pipeline.yaml
â”‚   â””â”€â”€ experiments/              # Configs de experimentos
â”‚       â””â”€â”€ ocr_comparison.yaml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ocr/                      # MÃ³dulo OCR
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tesseract.py
â”‚   â”‚   â”‚   â”œâ”€â”€ easyocr.py
â”‚   â”‚   â”‚   â”œâ”€â”€ paddleocr.py
â”‚   â”‚   â”‚   â””â”€â”€ trocr.py
â”‚   â”‚   â”œâ”€â”€ preprocessors.py
â”‚   â”‚   â”œâ”€â”€ postprocessors.py
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â””â”€â”€ pipeline/                 # Pipelines
â”‚       â”œâ”€â”€ base.py
â”‚       â”œâ”€â”€ detection.py
â”‚       â”œâ”€â”€ ocr.py
â”‚       â””â”€â”€ expiry_date.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â””â”€â”€ install_ocr_engines.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ prepare_ocr_dataset.py
â”‚   â”‚   â””â”€â”€ annotate_ground_truth.py
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ benchmark_ocrs.py
â”‚   â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”‚   â””â”€â”€ visualize_results.py
â”‚   â””â”€â”€ experiments/
â”‚       â””â”€â”€ run_ocr_comparison.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ocr_test/                 # Dataset OCR
â”‚       â”œâ”€â”€ images/               # Crops das datas
â”‚       â”œâ”€â”€ metadata.json
â”‚       â””â”€â”€ ground_truth.json
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ ocr_benchmarks/           # Resultados dos benchmarks
    â”œâ”€â”€ preprocessing_tests/      # Testes de prÃ©-processamento
    â””â”€â”€ visualizations/           # GrÃ¡ficos e visualizaÃ§Ãµes
```

---

## ğŸ’¡ Exemplos de Uso

### Exemplo 1: Teste RÃ¡pido de um Engine

```bash
# Preparar dados
make ocr-prepare-data DETECTIONS=outputs/predictions

# Anotar ground truth (interface grÃ¡fica)
make ocr-annotate

# Testar PaddleOCR
make ocr-test ENGINE=paddleocr
```

### Exemplo 2: ComparaÃ§Ã£o Completa

```bash
# Workflow completo automÃ¡tico
make workflow-ocr

# Ver resultados
cat outputs/ocr_benchmarks/comparison/comparison_summary.csv
```

### Exemplo 3: Pipeline End-to-End

```bash
# Executar pipeline completo em uma imagem
make pipeline-run IMAGE=data/test_images/produto.jpg

# Ver resultado em outputs/pipeline_test/
```

### Exemplo 4: Experimento para TCC

```bash
# Executar experimento completo de comparaÃ§Ã£o
make exp-ocr-comparison

# Resultados detalhados em:
# - outputs/ocr_benchmarks/comparison/
# - outputs/preprocessing_tests/
# - outputs/visualizations/
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### config/ocr/paddleocr.yaml

```yaml
engine: paddleocr
model_version: 'v4'
det_model: 'ch_PP-OCRv4_det'
rec_model: 'ch_PP-OCRv4_rec'

use_angle_cls: true
use_gpu: true
show_log: false

det_db_thresh: 0.3
rec_batch_num: 6
```

### config/preprocessing/medium.yaml

```yaml
name: medium
steps:
  - resize:
      min_height: 48
      min_width: 200
      maintain_aspect: true
  
  - grayscale:
      enabled: true
  
  - clahe:
      enabled: true
      clip_limit: 2.0
      tile_grid_size: [8, 8]
  
  - threshold:
      method: adaptive_gaussian
      block_size: 11
      c: 2
  
  - padding:
      enabled: true
      size: 10
      color: 255
```

### config/pipeline/full_pipeline.yaml

```yaml
name: expiry_date_full_pipeline

detection:
  model_path: models/detection/yolov8s-seg/best.pt
  confidence: 0.25
  iou: 0.7
  device: 0

ocr:
  config: config/ocr/paddleocr.yaml
  preprocessing: config/preprocessing/medium.yaml

parsing:
  date_formats:
    - '%d/%m/%Y'
    - '%d/%m/%y'
    - '%d.%m.%Y'
    - '%d-%m-%Y'
  validation:
    min_year: 2024
    max_year: 2030
```

---

## ğŸ“Š MÃ©tricas Avaliadas

### MÃ©tricas OCR

- **Exact Match Rate**: % de textos extraÃ­dos exatamente iguais ao ground truth
- **Partial Match Rate**: % de textos com correspondÃªncia parcial
- **Character Error Rate (CER)**: DistÃ¢ncia de Levenshtein normalizada
- **Processing Time**: Tempo mÃ©dio por imagem

### Resultados Esperados

Com dataset bem anotado:

| Engine | Exact Match | CER | Tempo (ms) |
|--------|-------------|-----|-----------|
| PaddleOCR | ~85-95% | 0.05-0.10 | 100-200 |
| EasyOCR | ~80-90% | 0.08-0.15 | 150-300 |
| TrOCR | ~85-95% | 0.05-0.12 | 300-500 |
| Tesseract | ~70-85% | 0.10-0.20 | 50-100 |

---

## ğŸ› Troubleshooting

### Problema: Tesseract nÃ£o encontrado

```bash
# Verifique instalaÃ§Ã£o
tesseract --version

# Windows: adicione ao PATH
# C:\Program Files\Tesseract-OCR
```

### Problema: GPU nÃ£o detectada

```bash
# Teste CUDA
python -c "import torch; print(torch.cuda.is_available())"

# Configure para usar CPU nos arquivos YAML:
# use_gpu: false
```

### Problema: Ground truth vazio

Use a interface de anotaÃ§Ã£o:

```bash
make ocr-annotate
```

Ou anote manualmente o arquivo JSON.

---

## ğŸ“š ReferÃªncias

- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
- [EasyOCR](https://github.com/JaidedAI/EasyOCR)
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)
- [TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)

---

## ğŸ“ Para o TCC

### Experimentos Sugeridos

1. **ComparaÃ§Ã£o de Engines**: `make ocr-compare`
2. **Ablation Study de PrÃ©-processamento**: `make prep-compare`
3. **AnÃ¡lise de Erros**: Verificar tipos de erro mais comuns
4. **Performance vs AcurÃ¡cia**: Trade-off entre velocidade e precisÃ£o

### VisualizaÃ§Ãµes para o TCC

- GrÃ¡ficos de comparaÃ§Ã£o (gerados automaticamente)
- Tabelas de mÃ©tricas (CSV)
- Exemplos de acertos/erros (salvos durante benchmark)
- Curvas de performance por engine

---

**Desenvolvido para o TCC - DetecÃ§Ã£o de Datas de Validade** ğŸ“

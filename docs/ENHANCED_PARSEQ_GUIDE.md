# üéØ Guia Completo: Enhanced PARSeq OCR

## üìã √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Melhorias Implementadas](#melhorias-implementadas)
3. [Configura√ß√£o e Uso](#configura√ß√£o-e-uso)
4. [Par√¢metros Recomendados](#par√¢metros-recomendados)
5. [Experimenta√ß√£o e Avalia√ß√£o](#experimenta√ß√£o-e-avalia√ß√£o)
6. [Fine-tuning (Opcional)](#fine-tuning-opcional)
7. [Troubleshooting](#troubleshooting)

---

## üéØ Vis√£o Geral

Este pipeline aprimorado de OCR com PARSeq implementa todas as melhorias solicitadas para maximizar acur√°cia em imagens multi-linha com varia√ß√£o de fontes, cores, √¢ngulos e crops heterog√™neos.

### Pipeline Completo

```
Input Image
    ‚Üì
[1] Line Detection & Splitting
    ‚Üì (para cada linha)
[2] Geometric Normalization (deskew, perspective)
    ‚Üì
[3] Photometric Normalization (denoise, shadow removal, CLAHE)
    ‚Üì
[4] Variant Generation (ensemble)
    ‚Üì
[5] PARSeq Inference (m√∫ltiplas variantes)
    ‚Üì
[6] Reranking (confian√ßa + formato + contexto)
    ‚Üì
[7] Contextual Post-processing (ambiguity mapping, fuzzy match)
    ‚Üì
Output Text + Confidence
```

---

## üöÄ Melhorias Implementadas

### ‚úÖ 1. Line Detection & Splitting

**Arquivo:** `src/ocr/line_detector.py`

**Funcionalidades:**
- ‚úÖ Detec√ß√£o autom√°tica de rota√ß√£o (Hough Transform)
- ‚úÖ Corre√ß√£o de pequenas rota√ß√µes (at√© 5¬∞ por padr√£o)
- ‚úÖ Clustering DBSCAN ou Agglomerative para agrupar componentes por Y
- ‚úÖ M√©todo h√≠brido: projection profile + clustering
- ‚úÖ Splitting em m√∫ltiplas imagens (uma por linha)

**Novos Par√¢metros:**
```python
line_detector_config = {
    'method': 'hybrid',  # 'projection', 'clustering', 'morphology', 'hybrid'
    'min_line_height': 10,
    'max_line_gap': 5,
    'dbscan_eps': 15,
    'enable_rotation_detection': True,
    'max_rotation_angle': 5.0,
    'clustering_method': 'dbscan'  # ou 'agglomerative'
}
```

### ‚úÖ 2. Normaliza√ß√£o Geom√©trica

**Arquivo:** `src/ocr/normalizers.py` (classe `GeometricNormalizer`)

**Funcionalidades:**
- ‚úÖ Deskew robusto com limite de √¢ngulo
- ‚úÖ Perspective warp com **sanity checks aprimorados**:
  - Verifica√ß√£o de √°rea do contorno (>30% da imagem)
  - Valida√ß√£o de aspect ratio (<20:1)
  - Limite de √¢ngulo de rota√ß√£o (<15¬∞)
  - Verifica√ß√£o de dimens√µes resultantes
- ‚úÖ Resize para m√∫ltiplas alturas (32, 64, 128px)
- ‚úÖ Mant√©m aspect ratio

**Sanity Checks Adicionados:**
```python
# 1. Contorno muito pequeno
if contour_area < 0.3 * image_area:
    return image  # Pula warp

# 2. Aspect ratio extremo
if aspect > 20:
    return image

# 3. √Çngulo muito grande
if angle > 15:
    return image

# 4. Dimens√µes resultantes muito grandes
if width > max_dim * 2 or height > max_dim * 2:
    return image
```

### ‚úÖ 3. Normaliza√ß√£o Fotom√©trica Adaptativa

**Arquivo:** `src/ocr/normalizers.py` (classe `PhotometricNormalizer`)

**Funcionalidades:**
- ‚úÖ Denoise: median (3x3) ou bilateral (d=7)
- ‚úÖ Shadow removal: blur subtraction (ksize=21)
- ‚úÖ CLAHE leve (clip_limit=1.5, tile_grid=8x8)
- ‚úÖ **7 variantes geradas**:
  1. `baseline`: denoise apenas
  2. `clahe`: CLAHE padr√£o (clip_limit=1.5)
  3. `clahe_strong`: CLAHE agressivo (clip_limit=2.5)
  4. `threshold`: Otsu threshold
  5. `invert`: threshold invertido
  6. `adaptive_threshold`: threshold adaptativo (blockSize=11)
  7. `sharp`: com sharpening

**Par√¢metros Recomendados:**
```python
photometric_config = {
    'denoise_method': 'bilateral',  # Melhor para texto
    'shadow_removal': True,
    'clahe_enabled': True,
    'clahe_clip_limit': 1.5,  # 1.2-1.6 range ideal
    'clahe_tile_grid': [8, 8],  # 4x4 ou 8x8
    'sharpen_enabled': True,
    'sharpen_strength': 0.3
}
```

### ‚úÖ 4. Infer√™ncia PARSeq & Ensemble

**Arquivo:** `src/ocr/engines/parseq_enhanced.py`

**Funcionalidades:**
- ‚úÖ Gera√ß√£o de variantes por linha
- ‚úÖ OCR em cada variante
- ‚úÖ **Reranking aprimorado** com scoring multi-fator:
  - Confian√ßa do modelo (peso 50%)
  - Match de formato via regex (bonus +0.2)
  - Palavras-chave (LOT, LOTE: +0.15)
  - Score contextual do postprocessor (+20%)
  - Penalidades (texto curto: -0.3, s√≠mbolos: -0.2, espa√ßos: -0.15)

**Estrat√©gias de Ensemble:**
- `confidence`: escolhe maior confian√ßa
- `voting`: voto majorit√°rio
- `rerank`: scoring combinado (recomendado)

### ‚úÖ 5. P√≥s-processamento Contextual

**Arquivo:** `src/ocr/postprocessor_context.py`

**Funcionalidades:**
- ‚úÖ Uppercase normaliza√ß√£o
- ‚úÖ Remo√ß√£o de s√≠mbolos indesejados
- ‚úÖ **Mapeamento contextual inteligente**:
  - Contexto num√©rico: O‚Üí0, I‚Üí1, S‚Üí5, etc.
  - Contexto alfab√©tico: 0‚ÜíO, 1‚ÜíI (apenas se isolado)
- ‚úÖ **Fuzzy matching** com edit distance (Levenshtein)
  - Corre√ß√£o de palavras conhecidas (LOT, LOTE, DATE, etc.)
  - Threshold: 30% de diferen√ßa permitida
- ‚úÖ Corre√ß√£o de formatos conhecidos:
  - LOT/LOTE: `L0TE` ‚Üí `LOTE`
  - Datas: normaliza separadores para `/`
  - C√≥digos alfanum√©ricos: remove espa√ßos

**Novos Par√¢metros:**
```python
postprocessor_config = {
    'uppercase': True,
    'remove_symbols': False,
    'ambiguity_mapping': True,
    'fix_formats': True,
    'enable_fuzzy_match': True,
    'fuzzy_threshold': 2,
    'known_words': ['LOT', 'LOTE', 'DATE', 'BATCH', 'MFG', 'EXP']
}
```

### ‚úÖ 6. Utilit√°rios de Experimenta√ß√£o

**Arquivo:** `src/ocr/experiment_utils.py`

**Funcionalidades:**
- ‚úÖ `ExperimentRunner`: executa ablation tests
- ‚úÖ C√°lculo autom√°tico de m√©tricas:
  - CER (Character Error Rate)
  - WER (Word Error Rate)
  - Exact Match Rate
  - Line ordering errors
- ‚úÖ `ConfigurationPresets`: presets para ablation
- ‚úÖ Salvamento de resultados em JSON

---

## üìñ Configura√ß√£o e Uso

### Instala√ß√£o de Depend√™ncias

```bash
# Depend√™ncias opcionais para melhor performance
pip install python-Levenshtein  # Para fuzzy matching r√°pido
pip install scikit-learn  # Para clustering (DBSCAN, Agglomerative)
```

### Uso B√°sico

```python
from src.ocr.engines.parseq_enhanced import EnhancedPARSeqEngine
from src.ocr.experiment_utils import RECOMMENDED_PARAMS
import cv2

# Configura√ß√£o recomendada
config = {
    'model_name': 'parseq_tiny',  # 'parseq', 'parseq_patch16_224'
    'device': 'cuda',  # ou 'cpu'
    
    # Habilitar pipeline completo
    'enable_line_detection': True,
    'enable_geometric_norm': True,
    'enable_photometric_norm': True,
    'enable_ensemble': True,
    'ensemble_strategy': 'rerank',
    
    # Componentes com par√¢metros otimizados
    'line_detector': RECOMMENDED_PARAMS['line_detector'],
    'geometric_normalizer': RECOMMENDED_PARAMS['geometric_normalizer'],
    'photometric_normalizer': RECOMMENDED_PARAMS['photometric_normalizer'],
    'postprocessor': RECOMMENDED_PARAMS['postprocessor']
}

# Inicializar
engine = EnhancedPARSeqEngine(config)
engine.initialize()

# Processar imagem
image = cv2.imread('path/to/image.jpg')
text, confidence = engine.extract_text(image)

print(f"Texto: {text}")
print(f"Confian√ßa: {confidence:.2%}")
```

### Script Demo

```bash
# Processar imagem √∫nica
python scripts/ocr/demo_enhanced_parseq.py \
    --mode single \
    --image data/ocr_test/sample.jpg

# Ablation test
python scripts/ocr/demo_enhanced_parseq.py \
    --mode ablation \
    --image data/ocr_test/sample.jpg \
    --ground-truth "LOT123 20/10/2024"

# Batch processing
python scripts/ocr/demo_enhanced_parseq.py \
    --mode batch \
    --image-dir data/ocr_test/ \
    --output outputs/demo/results.csv
```

---

## ‚öôÔ∏è Par√¢metros Recomendados

### Por Tipo de Imagem

#### 1Ô∏è‚É£ Imagens de Alta Qualidade (limpa, bem iluminada)

```python
config = {
    'enable_line_detection': True,
    'enable_geometric_norm': True,
    'enable_photometric_norm': False,  # N√£o necess√°rio
    'enable_ensemble': False,  # Variante √∫nica √© suficiente
    
    'photometric_normalizer': {
        'denoise_method': 'none',
        'clahe_enabled': False
    }
}
```

#### 2Ô∏è‚É£ Imagens com Sombras/Ilumina√ß√£o Irregular

```python
config = {
    'enable_photometric_norm': True,
    'enable_ensemble': True,
    
    'photometric_normalizer': {
        'denoise_method': 'bilateral',
        'shadow_removal': True,  # ‚≠ê Importante
        'clahe_enabled': True,
        'clahe_clip_limit': 1.6,  # Mais agressivo
        'clahe_tile_grid': [8, 8]
    }
}
```

#### 3Ô∏è‚É£ Imagens com Rota√ß√£o/Perspectiva

```python
config = {
    'enable_geometric_norm': True,
    
    'line_detector': {
        'enable_rotation_detection': True,
        'max_rotation_angle': 10.0  # Permitir rota√ß√µes maiores
    },
    
    'geometric_normalizer': {
        'enable_deskew': True,
        'max_angle': 15,
        'enable_perspective': False  # Cuidado: pode distorcer
    }
}
```

#### 4Ô∏è‚É£ Imagens Dif√≠ceis (baixa qualidade, multi-linha, varia√ß√£o alta)

```python
config = {
    # Tudo habilitado
    'enable_line_detection': True,
    'enable_geometric_norm': True,
    'enable_photometric_norm': True,
    'enable_ensemble': True,
    'ensemble_strategy': 'rerank',  # ‚≠ê Importante
    
    # Par√¢metros agressivos
    'photometric_normalizer': {
        'denoise_method': 'bilateral',
        'shadow_removal': True,
        'clahe_clip_limit': 1.8,  # Mais contraste
        'sharpen_enabled': True,
        'sharpen_strength': 0.5
    },
    
    'line_detector': {
        'method': 'hybrid',  # ‚≠ê Melhor para casos complexos
        'clustering_method': 'agglomerative'  # Mais est√°vel
    }
}
```

### Valores Testados e Recomendados

| Par√¢metro | Min | Recomendado | Max | Observa√ß√£o |
|-----------|-----|-------------|-----|------------|
| `clahe_clip_limit` | 1.0 | **1.2-1.6** | 3.0 | >2.0 amplifica ru√≠do |
| `clahe_tile_grid` | (4,4) | **(8,8)** | (16,16) | Maior = mais local |
| `shadow_ksize` | 11 | **21** | 51 | Deve ser √≠mpar |
| `dbscan_eps` | 5 | **15** | 30 | Dist√¢ncia entre linhas |
| `max_rotation_angle` | 0 | **5.0** | 15 | Limite seguro |
| `fuzzy_threshold` | 1 | **2** | 3 | Edit distance m√°xima |

---

## üß™ Experimenta√ß√£o e Avalia√ß√£o

### Ablation Test Autom√°tico

```python
from src.ocr.experiment_utils import ExperimentRunner, ConfigurationPresets
import cv2

# Preparar dados de teste
test_images = [cv2.imread(f"data/ocr_test/img_{i}.jpg") for i in range(10)]
ground_truths = ["LOT123", "20/10/2024", ...]  # Textos esperados

# Runner
runner = ExperimentRunner(output_dir="outputs/ablation")

# Configs para testar
configs = ConfigurationPresets.get_ablation_configs()

# Executar
results = runner.run_ablation_test(
    ocr_engine=engine,
    test_images=test_images,
    ground_truths=ground_truths,
    configurations=configs
)

# Resultados salvos em JSON automaticamente
```

### M√©tricas Calculadas

#### CER (Character Error Rate)
```
CER = edit_distance(predicted, ground_truth) / len(ground_truth)
```
- **Ideal:** < 0.05 (5% erro)
- **Aceit√°vel:** < 0.10 (10% erro)

#### Exact Match Rate
```
Exact Match = (predi√ß√µes exatas) / (total predi√ß√µes)
```
- **Ideal:** > 0.90 (90% de acertos exatos)
- **Aceit√°vel:** > 0.70 (70% de acertos)

### Checklist de Experimenta√ß√£o

- [ ] **Baseline**: testar sem melhorias
- [ ] **Line splitting**: isolar impacto da detec√ß√£o de linhas
- [ ] **Photometric norm**: avaliar CLAHE + shadow removal
- [ ] **Ensemble**: comparar variantes (baseline vs clahe vs threshold)
- [ ] **Postprocessing**: medir ganho do mapeamento contextual
- [ ] **Full pipeline**: validar pipeline completo

### Exemplo de Resultados Esperados

```
Configura√ß√£o            | CER    | Exact Match | Tempo
------------------------|--------|-------------|-------
1_baseline              | 0.1523 | 45%         | 0.8s
2_line_detection        | 0.1204 | 58%         | 1.2s
3_geometric_norm        | 0.0987 | 65%         | 1.5s
4_photometric_norm      | 0.0756 | 72%         | 1.8s
5_ensemble              | 0.0521 | 84%         | 3.2s
6_full_pipeline         | 0.0312 | 91%         | 3.5s
```

---

## üéì Fine-tuning (Opcional)

### Quando Fine-tunar?

Fine-tune o PARSeq se:
- CER do pipeline completo > 0.10 (10%)
- Exact Match < 70%
- Dom√≠nio muito espec√≠fico (fontes √∫nicas, formatos customizados)

### Requisitos

- **500-2000 exemplos anotados por linha**
- Anota√ß√µes precisas (character-level)
- Diversidade de varia√ß√µes (fontes, cores, √¢ngulos)

### Augmentation para Training

```python
from albumentations import Compose, RandomRotate90, GridDistortion, 
    OpticalDistortion, ElasticTransform, CLAHE, RandomBrightnessContrast, 
    GaussNoise, Blur, MotionBlur, Perspective

augmentation = Compose([
    # Geom√©trico
    RandomRotate90(p=0.3),
    Perspective(scale=(0.05, 0.1), p=0.5),
    ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
    
    # Fotom√©trico
    RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),
    CLAHE(clip_limit=4.0, p=0.5),
    
    # Ru√≠do
    GaussNoise(var_limit=(10, 50), p=0.3),
    MotionBlur(blur_limit=7, p=0.3),
    
    # Sombras (custom)
    # ... implementar shadow augmentation
])
```

### Passos para Fine-tuning

1. **Preparar dataset:**
   ```
   data/
     train/
       image_001.jpg
       image_001.txt
       ...
     val/
       ...
   ```

2. **Configurar training:**
   - Learning rate: 1e-4 a 5e-5
   - Batch size: 16-32 (depende de GPU)
   - Epochs: 10-50
   - Early stopping: patience=5

3. **Executar training** (use repo oficial baudm/parseq)

4. **Validar modelo fine-tuned** no seu pipeline

---

## üõ†Ô∏è Troubleshooting

### Problema: CER ainda alto ap√≥s pipeline completo

**Poss√≠veis causas:**
1. ‚ùå Imagens muito degradadas
2. ‚ùå Fontes muito diferentes do training do PARSeq
3. ‚ùå Multi-script (alfabetos mistos)

**Solu√ß√µes:**
- ‚úÖ Aumentar `clahe_clip_limit` para 1.8-2.0
- ‚úÖ Habilitar mais variantes (adaptive_threshold √∫til)
- ‚úÖ Considerar fine-tuning
- ‚úÖ Testar modelo maior (`parseq` ou `parseq_patch16_224`)

### Problema: Linhas n√£o detectadas corretamente

**Causas:**
- ‚ùå `min_line_height` muito alto
- ‚ùå `dbscan_eps` inadequado
- ‚ùå Rota√ß√£o muito grande n√£o corrigida

**Solu√ß√µes:**
- ‚úÖ Reduzir `min_line_height` para 8-10
- ‚úÖ Ajustar `dbscan_eps` (dist√¢ncia t√≠pica entre linhas)
- ‚úÖ Aumentar `max_rotation_angle` para 10-15
- ‚úÖ Usar `clustering_method='agglomerative'`

### Problema: Texto invertido (branco em preto)

**Solu√ß√£o:**
- ‚úÖ A variante `invert` j√° trata isso automaticamente
- ‚úÖ Se n√£o funcionar, adicionar preprocessamento customizado

### Problema: Processamento muito lento

**Causas:**
- ‚ùå Muitas variantes no ensemble
- ‚ùå Imagens muito grandes
- ‚ùå CPU ao inv√©s de GPU

**Solu√ß√µes:**
- ‚úÖ Reduzir variantes (desabilitar adaptive_threshold e sharp)
- ‚úÖ Resize imagens antes: max 1000px de largura
- ‚úÖ Usar `device='cuda'` se dispon√≠vel
- ‚úÖ Desabilitar ensemble para imagens simples

### Problema: python-Levenshtein n√£o instalado

**Solu√ß√£o:**
```bash
pip install python-Levenshtein
```

Se falhar no Windows:
```bash
pip install python-Levenshtein-wheels
```

---

## üìä Resumo das Melhorias

| Melhoria | Ganho Esperado | Complexidade | Prioridade |
|----------|----------------|--------------|------------|
| Line detection + rotation | +15-25% accuracy | M√©dia | ‚≠ê‚≠ê‚≠ê Alta |
| Shadow removal + CLAHE | +10-20% accuracy | Baixa | ‚≠ê‚≠ê‚≠ê Alta |
| Ensemble de variantes | +5-15% accuracy | M√©dia | ‚≠ê‚≠ê M√©dia |
| Postprocessing contextual | +5-10% accuracy | Baixa | ‚≠ê‚≠ê M√©dia |
| Fine-tuning PARSeq | +20-40% accuracy | Alta | ‚≠ê Baixa* |

*Baixa prioridade se pipeline gen√©rico j√° atingir >85% exact match

---

## üìö Refer√™ncias

- **PARSeq:** https://github.com/baudm/parseq
- **CLAHE:** Adaptive Histogram Equalization
- **DBSCAN:** Density-Based Spatial Clustering
- **Levenshtein Distance:** Edit distance para fuzzy matching

---

**Desenvolvido para maximizar acur√°cia OCR em cen√°rios desafiadores** üöÄ

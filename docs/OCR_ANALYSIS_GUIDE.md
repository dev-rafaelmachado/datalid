# üìä Guia de An√°lise Detalhada de OCR

Este guia explica como usar o sistema de avalia√ß√£o aprimorado com visualiza√ß√µes e estat√≠sticas detalhadas.

## üéØ Vis√£o Geral

O m√≥dulo de visualiza√ß√£o e an√°lise foi expandido para fornecer:

- **Estat√≠sticas Detalhadas**: M√©tricas completas de performance
- **Visualiza√ß√µes Gr√°ficas**: Gr√°ficos comparativos e distribui√ß√µes
- **An√°lise de Erros**: Categoriza√ß√£o e exemplos de erros
- **Relat√≥rio HTML**: Relat√≥rio interativo com todas as informa√ß√µes
- **An√°lise de Caracteres**: Identifica√ß√£o de erros comuns
- **An√°lise de Confian√ßa**: Correla√ß√£o entre confian√ßa e precis√£o

## üöÄ Como Usar

### 1. Avalia√ß√£o Simples

```bash
# Avaliar um engine OCR
python scripts/ocr/evaluate_with_analysis.py \
    --engine parseq_enhanced \
    --test-data data/ocr_test \
    --output outputs/ocr_analysis
```

### 2. Avalia√ß√£o com Pr√©-processamento

```bash
# Avaliar com pr√©-processamento espec√≠fico
python scripts/ocr/evaluate_with_analysis.py \
    --engine parseq_enhanced \
    --test-data data/ocr_test \
    --output outputs/ocr_analysis \
    --preprocessing ppro-parseq
```

### 3. Avalia√ß√£o com Configura√ß√£o Customizada

```bash
# Avaliar com config customizada
python scripts/ocr/evaluate_with_analysis.py \
    --engine parseq_enhanced \
    --config config/ocr/parseq_enhanced.yaml \
    --test-data data/ocr_test \
    --output outputs/ocr_analysis \
    --preprocessing ppro-parseq
```

## üìä Outputs Gerados

Ap√≥s a execu√ß√£o, os seguintes arquivos s√£o gerados:

### 1. Arquivos de Dados

- **`{engine}_results.csv`**: Resultados em formato CSV
- **`{engine}_results.json`**: Resultados em formato JSON
- **`statistics.json`**: Estat√≠sticas completas em JSON

### 2. Visualiza√ß√µes

- **`overview.png`**: Vis√£o geral das m√©tricas
  - Exact Match Rate
  - CER Distribution
  - Confidence Distribution
  - Error Categories
  - Processing Time
  - Confidence vs CER Scatter

- **`error_distribution.png`**: An√°lise de distribui√ß√£o de erros
  - Box Plot de CER
  - Violin Plot de CER

- **`confidence_analysis.png`**: An√°lise de confian√ßa
  - CER por faixa de confian√ßa
  - Scatter com linha de tend√™ncia

- **`length_analysis.png`**: An√°lise de comprimento
  - CER por comprimento de texto
  - Scatter comprimento vs CER

- **`time_analysis.png`**: An√°lise de tempo
  - Distribui√ß√£o de tempo de processamento
  - Tempo vs CER

- **`engine_comparison.png`**: Compara√ß√£o entre engines (se houver m√∫ltiplos)
  - Exact Match por engine
  - CER por engine
  - Tempo por engine
  - Confian√ßa por engine

### 3. Relat√≥rio HTML

- **`report.html`**: Relat√≥rio interativo completo
  - Todas as estat√≠sticas
  - Todas as visualiza√ß√µes embutidas
  - An√°lise de erros categorizada
  - Navega√ß√£o f√°cil

## üìà Estat√≠sticas Dispon√≠veis

### Estat√≠sticas B√°sicas

```json
{
  "basic": {
    "total_samples": 100,
    "exact_match_rate": 0.85,
    "partial_match_rate": 0.92,
    "avg_cer": 0.042,
    "median_cer": 0.015,
    "std_cer": 0.056,
    "avg_similarity": 0.95,
    "avg_confidence": 0.88,
    "avg_processing_time": 0.145,
    "total_processing_time": 14.5,
    "cer_percentiles": {
      "p25": 0.0,
      "p50": 0.015,
      "p75": 0.055,
      "p90": 0.120,
      "p95": 0.185
    }
  }
}
```

### An√°lise de Erros

```json
{
  "errors": {
    "perfect": {
      "count": 65,
      "percentage": 65.0
    },
    "low_error": {
      "count": 20,
      "percentage": 20.0,
      "avg_cer": 0.08
    },
    "medium_error": {
      "count": 10,
      "percentage": 10.0,
      "avg_cer": 0.35
    },
    "high_error": {
      "count": 5,
      "percentage": 5.0,
      "avg_cer": 0.68,
      "examples": [...]
    }
  }
}
```

### An√°lise de Caracteres

```json
{
  "characters": {
    "most_deleted": [
      ["0", 15],
      ["1", 12],
      ["/", 8]
    ],
    "most_inserted": [
      ["O", 10],
      ["l", 8]
    ]
  }
}
```

### An√°lise de Comprimento

```json
{
  "length_analysis": {
    "0-5": {
      "count": 20,
      "avg_cer": 0.02,
      "exact_match_rate": 0.95
    },
    "6-10": {
      "count": 40,
      "avg_cer": 0.04,
      "exact_match_rate": 0.85
    },
    "11-15": {
      "count": 30,
      "avg_cer": 0.05,
      "exact_match_rate": 0.80
    }
  }
}
```

### An√°lise de Confian√ßa

```json
{
  "confidence_analysis": {
    "0.9-1.0": {
      "count": 60,
      "avg_cer": 0.02,
      "exact_match_rate": 0.95
    },
    "0.8-0.9": {
      "count": 25,
      "avg_cer": 0.05,
      "exact_match_rate": 0.80
    },
    "correlation_with_cer": -0.65
  }
}
```

## üîç Uso Program√°tico

Voc√™ tamb√©m pode usar o visualizador diretamente no c√≥digo:

```python
from src.ocr.evaluator import OCREvaluator
from src.ocr.visualization import OCRVisualizer
import pandas as pd

# Criar evaluator
evaluator = OCREvaluator()
evaluator.add_engine('parseq_enhanced', 'config/ocr/parseq_enhanced.yaml')

# Avaliar dataset
df = evaluator.evaluate_dataset(
    dataset_path='data/ocr_test/images',
    ground_truth_path='data/ocr_test/ground_truth.json'
)

# Gerar an√°lise detalhada
stats = evaluator.generate_detailed_analysis(
    df,
    output_dir='outputs/ocr_analysis'
)

# Ou usar visualizador diretamente
results = df.to_dict('records')
visualizer = OCRVisualizer(results, 'outputs/custom_analysis')

# Gerar tudo
all_stats = visualizer.generate_all(save_plots=True)

# Ou gerar componentes individuais
basic_stats = visualizer.calculate_basic_stats()
error_analysis = visualizer.analyze_errors()
visualizer.plot_overview()
visualizer.plot_confidence_analysis()
html_report = visualizer.generate_html_report(all_stats)
```

## üìã Checklist de Avalia√ß√£o

- [ ] Preparar dados de teste com ground truth
- [ ] Escolher engine(s) para avaliar
- [ ] Configurar pr√©-processamento (se necess√°rio)
- [ ] Executar avalia√ß√£o
- [ ] Analisar relat√≥rio HTML
- [ ] Verificar gr√°ficos de distribui√ß√£o
- [ ] Identificar casos de erro alto
- [ ] Comparar estat√≠sticas
- [ ] Ajustar configura√ß√µes baseado nos resultados

## üé® Interpretando os Gr√°ficos

### Overview
- **Exact Match**: Deve ser > 80% para boa performance
- **CER Distribution**: Concentra√ß√£o em valores baixos √© desej√°vel
- **Confidence**: Alta confian√ßa geralmente indica boa precis√£o
- **Error Categories**: Idealmente 70%+ em "Perfect"

### Error Distribution
- **Box Plot**: Mostra mediana, quartis e outliers
- **Violin Plot**: Mostra densidade da distribui√ß√£o

### Confidence Analysis
- **Boxplot por Range**: Confirma se alta confian√ßa = baixo erro
- **Scatter com Trend**: Correla√ß√£o negativa √© esperada

### Length Analysis
- Textos mais longos geralmente t√™m mais erros
- √ötil para identificar limites do modelo

### Time Analysis
- Identifica outliers de processamento
- √ötil para otimiza√ß√£o de performance

## üí° Dicas

1. **Compare m√∫ltiplos engines**: Execute para diferentes engines e compare
2. **Teste configura√ß√µes**: Experimente diferentes pr√©-processamentos
3. **Analise erros altos**: Foque nos casos com CER > 0.5
4. **Verifique correla√ß√£o**: Alta confian√ßa deve correlacionar com baixo erro
5. **Considere o contexto**: Alguns erros podem ser aceit√°veis dependendo do uso

## üîß Troubleshooting

### Matplotlib n√£o instalado
```bash
pip install matplotlib seaborn
```

### Gr√°ficos n√£o s√£o gerados
Use a flag `--skip-plots` para pular visualiza√ß√µes:
```bash
python scripts/ocr/evaluate_with_analysis.py --skip-plots ...
```

### Erro ao ler imagens
Verifique se as imagens est√£o em formato suportado (JPG, PNG)

### Ground truth inv√°lido
Verifique formato:
```json
{
  "annotations": {
    "image1.jpg": "expected text",
    "image2.jpg": "another text"
  }
}
```

## üìö Pr√≥ximos Passos

Ap√≥s analisar os resultados:

1. **Melhorar Pr√©-processamento**: Ajuste baseado em an√°lise de erros
2. **Otimizar Configura√ß√£o**: Tune hiperpar√¢metros do engine
3. **Aumentar Dataset**: Adicione mais exemplos de casos dif√≠ceis
4. **Ensemble**: Combine m√∫ltiplos engines para melhor resultado
5. **Post-processing**: Implemente corre√ß√µes contextuais

## üéØ Exemplo Completo

```bash
# 1. Avaliar baseline
python scripts/ocr/evaluate_with_analysis.py \
    --engine parseq \
    --test-data data/ocr_test \
    --output outputs/analysis/parseq_baseline

# 2. Avaliar com enhanced
python scripts/ocr/evaluate_with_analysis.py \
    --engine parseq_enhanced \
    --test-data data/ocr_test \
    --output outputs/analysis/parseq_enhanced

# 3. Comparar resultados
# Abra os relat√≥rios HTML lado a lado
# outputs/analysis/parseq_baseline/report.html
# outputs/analysis/parseq_enhanced/report.html
```

## üìß Suporte

Para mais informa√ß√µes, veja:
- `docs/OCR_QUICKSTART.md`
- `docs/ENHANCED_PARSEQ_GUIDE.md`
- `scripts/ocr/exemplo_parseq.py`
